<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><atom:link href="https://www.loicblanchard.me/blog/rss/clojure-feed.xml" rel="self" type="application/rss+xml"></atom:link><title>Loic Blanchard - Clojure Blog Feed</title><link>https://www.loicblanchard.me</link><description>Articles related to Clojure</description><language>en-us</language><lastBuildDate>Fri, 30 Aug 2024 16:16:25 +0000</lastBuildDate><generator>clj-rss</generator><item><title>Testing in Clojure</title><link>https://www.loicblanchard.me/blog/testing-in-clojure</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/testing-in-clojure</guid><pubDate>Sat, 10 Aug 2024 08:16:25 +0000</pubDate><description>
Introducing some popular testing tools to developers new to Clojure. Highlight solutions for how to do unit testing with Rich Comment Tests, data validation and generative testing with Malli, running test suites and metrics with Kaocha and how to do integration testing using external containerized services.
</description><content:encoded><![CDATA[<h2>Introduction</h2><p>This article introduces effective testing libraries and methods for those new to Clojure.</p><p>We'll explore using the <a href='https://github.com/lambdaisland/kaocha'>kaocha</a> test runner in both REPL and terminal, along with configurations to enhance feedback. Then we will explain how tests as documentation can be done using <a href='https://github.com/matthewdowney/rich-comment-tests'>rich-comment-tests</a>.</p><p>We will touch on how to do data validation, generation and instrumentation using <a href='https://github.com/metosin/malli'>malli</a>.</p><p>Finally, I will talk about how I manage integrations tests with eventual external services involved.</p><h2>Test good code</h2><h3>Pure functions</h3><p>First of all, always remember that it is important to have as many pure functions as possible. It means, the same input passed to a function always returns the same output. This will simplify the testing and make your code more robust.</p><p>Here is an example of unpredictable <strong>impure</strong> logic:</p><pre><code class="clojure">&#40;defn fib
  &quot;Read the Fibonacci list length to be returned from a file,
   Return the Fibonacci sequence.&quot;
  &#91;variable&#93;
  &#40;when-let &#91;n &#40;-&gt; &#40;slurp &quot;config/env.edn&quot;&#41; edn/read-string &#40;get variable&#41; :length&#41;&#93;
    &#40;-&gt;&gt; &#40;iterate &#40;fn &#91;&#91;a b&#93;&#93; &#91;b &#40;+' a b&#41;&#93;&#41;
                  &#91;0 1&#93;&#41;
         &#40;map first&#41;
         &#40;take n&#41;&#41;&#41;&#41;

&#40;comment
  ;; env.edn has the content {:FIB 10}
  &#40;fib :FIB&#41; ;=&gt; 10
  ;; env.edn is empty
  &#40;fib :FIB&#41; ;=&gt; nil
  &#41;
</code></pre><p>For instance, reading the <code>length</code> value from a file before computing the Fibonacci sequence is <strong>unpredictable</strong> for several reasons:</p><ul><li>the file could not have the expected value</li><li>the file could be missing</li><li>in prod, the env variable would be read from the system not a file so the function would always return <code>nil</code></li><li>what if the FIB value from the file has the wrong format.</li></ul><p>We would need to test too many cases unrelated to the Fibonacci logic itself, which is bad practice.</p><p>The solution is to <strong>isolate</strong> the impure code:</p><pre><code class="clojure">&#40;defn fib
  &quot;Return the Fibonacci sequence with a lenght of `n`.&quot;
  &#91;n&#93;
  &#40;-&gt;&gt; &#40;iterate &#40;fn &#91;&#91;a b&#93;&#93; &#91;b &#40;+' a b&#41;&#93;&#41;
                &#91;0 1&#93;&#41;
       &#40;map first&#41;
       &#40;take n&#41;&#41;&#41;

&#94;:rct/test
&#40;comment
  &#40;fib 10&#41; ;=&gt; &#91;0 1 1 2 3 5 8 13 21 34&#93;
  &#40;fib 0&#41; ;=&gt; &#91;&#93;
  &#41;

&#40;defn config&lt;-file
  &quot;Reads the `config/env.edn` file, gets the value of the given key `variable`
   and returns it as clojure data.&quot;
  &#91;variable&#93;
  &#40;-&gt; &#40;slurp &quot;config/env.edn&quot;&#41; edn/read-string &#40;get variable&#41;&#41;&#41;

&#40;comment
  ;; env.edn contains :FIB key with value {:length 10}
  &#40;config&lt;-file :FIB&#41; ;=&gt; {:length 10}
  ;; env.edn is empty
  &#40;config&lt;-file :FIB&#41; ;=&gt; {:length nil}
  &#41;
</code></pre><p>The <code>fib</code> function is now <strong>pure</strong> and the same input will always yield the same output. I can therefore write my unit tests and be confident of the result. You might have noticed I added <code>&#94;:rct/test</code> above the comment block which is actually a unit test that can be run with RCT (more on this later).</p><p>The <strong>impure</strong> code is isolated in the <code>config&lt;-file</code> function, which handles reading the environment variable from a file.</p><p>This may seem basic, but it's the essential first step in testing: ensuring the code is as pure as possible for easier testing is one of the strengths of <strong>data-oriented</strong> programming!</p><h2>Test runner: Kaocha</h2><p>For all my personal and professional projects, I have used <a href='https://github.com/lambdaisland/kaocha'>kaocha</a> as a test-runner. </p><p>There are 2 main ways to run the tests that developers commonly use:</p><ul><li>Within the <strong>REPL</strong> as we implement our features or fix bugs</li><li>In the <strong>terminal</strong>: to verify that all tests pass or to target a specific group of tests</li></ul><p>Here is the <code>deps.edn</code> I will use in this example:</p><pre><code class="clojure">{:deps {org.clojure/clojure {:mvn/version &quot;1.11.3&quot;}
        org.slf4j/slf4j-nop {:mvn/version &quot;2.0.15&quot;}
        metosin/malli       {:mvn/version &quot;0.16.1&quot;}}
 :paths &#91;&quot;src&quot;&#93;
 :aliases
 {:dev {:extra-paths &#91;&quot;config&quot; &quot;test&quot; &quot;dev&quot;&#93;
        :extra-deps {io.github.robertluo/rich-comment-tests {:git/tag &quot;v1.1.1&quot;, :git/sha &quot;3f65ecb&quot;}}}
  :test {:extra-paths &#91;&quot;test&quot;&#93;
         :extra-deps  {lambdaisland/kaocha           {:mvn/version &quot;1.91.1392&quot;}
                       lambdaisland/kaocha-cloverage {:mvn/version &quot;1.1.89&quot;}}
         :main-opts   &#91;&quot;-m&quot; &quot;kaocha.runner&quot;&#93;}
  :jib {:paths &#91;&quot;jibbit&quot; &quot;src&quot;&#93;
        :deps {io.github.atomisthq/jibbit {:git/url &quot;https://github.com/skydread1/jibbit.git&quot;
                                           :git/sha &quot;bd873e028c031dbbcb95fe3f64ff51a305f75b54&quot;}}
        :ns-default jibbit.core
        :ns-aliases {jib jibbit.core}}
  :outdated {:deps {com.github.liquidz/antq {:mvn/version &quot;RELEASE&quot;}}
             :main-opts &#91;&quot;-m&quot; &quot;antq.core&quot;&#93;}
  :cljfmt {:deps       {io.github.weavejester/cljfmt {:git/tag &quot;0.12.0&quot;, :git/sha &quot;434408f&quot;}}
           :ns-default cljfmt.tool}}}
</code></pre><h3>Kaocha in REPL</h3><p>Regarding the bindings to run the tests From the REPL, refer to your IDE documentation. I have experience using both Emacs (spacemacs distribution) and VSCode and running my tests was always straight forward. If you are starting to learn Clojure, I recommend using VSCode, as the Clojure extension <a href='https://github.com/BetterThanTomorrow/calva'>calva</a> is of very good quality and well documented. I‚Äôll use VSCode in the following example.</p><p>Let‚Äôs say we have the following test namespace:</p><pre><code class="clojure">&#40;ns my-app.core.fib-test
  &#40;:require &#91;clojure.test :refer &#91;deftest is testing&#93;&#93;
            &#91;my-app.core :as sut&#93;&#41;&#41;

&#40;deftest fib-test
  &#40;testing &quot;The Fib sequence is returned.&quot;
    &#40;is &#40;= &#91;0 1 1 2 3 5 8 13 21 34&#93;
           &#40;sut/fib 10&#41;&#41;&#41;&#41;&#41;
</code></pre><p>After I <code>jack-in</code> using my <em>dev</em> alias form the <code>deps.edn</code> file, I can load the <code>my-app.core-test</code> namespace and run the tests. Using Calva, the flow will be like this:</p><ol><li><em>ctrl+alt+c</em> <em>ctrl+alt+j</em>: jack-in (select the <code>dev</code> alias in my case)</li><li><em>ctrl+alt+c</em> <em>enter</em> (in the <code>fib-test</code> namespace): load the ns in the REPL</li><li><em>ctrl+alt+c</em> <em>t</em> (in the <code>fib-test</code> namespace): run the tests</li></ol><p>In the REPL, we see:</p><pre><code class="clojure">cljÍûâuserÍûâ&gt;
; Evaluating file: fib&#95;test.clj
#'my-app.core.fib-test/system-test
cljÍûâmy-app.core.fib-testÍûâ&gt;¬†
; Running tests for the following namespaces:
;   my-app.core.fib-test
;   my-app.core.fib

; 1 tests finished, all passing üëç, ns: 1, vars: 1
</code></pre><h3>Kaocha in terminal</h3><p>Before committing code, it's crucial to run all project tests to ensure new changes haven't broken existing functionalities.</p><p>I added a few other namespaces and some tests.</p><p>Let‚Äôs run all the tests in the terminal:</p><pre><code class="clojure">clj -M:dev:test
Loading namespaces:  &#40;my-app.core.cfg my-app.core.env my-app.core.fib my-app.core&#41;
Test namespaces:  &#40;:system :unit&#41;
Instrumented my-app.core.cfg
Instrumented my-app.core.env
Instrumented my-app.core.fib
Instrumented my-app.core
Instrumented 4 namespaces in 0.4 seconds.
malli: instrumented 1 function vars
malli: dev-mode started
&#91;&#40;.&#41;&#93;&#91;&#40;&#40;&#41;&#40;..&#41;&#40;..&#41;&#40;..&#41;&#41;&#40;.&#41;&#40;.&#41;&#93;
4 tests, 9 assertions, 0 failures.
</code></pre><p>Note the <code>Test namespaces: &#40;:system :unit&#41;</code>.  By default, Kaocha runs all tests. When no metadata is specified on the <code>deftest</code>, it is considered in the Kaocha <code>:unit</code> group. However, as the project grows, we might have slower tests that are system tests, load tests, stress tests etc. We can add metadata to their <code>deftest</code> in order to group them together. For instance:</p><pre><code class="clojure">&#40;ns my-app.core-test
  &#40;:require &#91;clojure.test :refer &#91;deftest is testing&#93;&#93;
            &#91;malli.dev :as dev&#93;
            &#91;malli.dev.pretty :as pretty&#93;
            &#91;my-app.core :as sut&#93;&#41;&#41;

&#40;dev/start! {:report &#40;pretty/reporter&#41;}&#41;

&#40;deftest &#94;:system system-test ;; metadata to add this test in the `system` kaocha test group 
  &#40;testing &quot;The Fib sequence is returned.&quot;
    &#40;is &#40;= &#91;0 1 1 2 3 5 8 13 21 34&#93;
           &#40;sut/system #:cfg{:app #:app{:name &quot;app&quot; :version &quot;1.0.0&quot;}
                             :fib #:fib{:length 10}}&#41;&#41;&#41;&#41;&#41;
</code></pre><p>We need to tell Kaocha when and how to run the system test. Kaocha configurations are provided in a <code>tests.edn</code> file:</p><pre><code class="clojure">#kaocha/v1
 {:tests &#91;{:id :system :focus-meta &#91;:system&#93;} ;; only system tests
          {:id :unit}&#93;} ;; all tests
</code></pre><p>Then in the terminal:</p><pre><code class="bash">clj -M:dev:test --focus :system
malli: instrumented 1 function vars
malli: dev-mode started
&#91;&#40;.&#41;&#93;
1 tests, 1 assertions, 0 failures.
</code></pre><p>We can add a bunch of metrics on top of the tests results. These metrics can be added via the <code>:plugins</code> keys:</p><pre><code class="clojure">#kaocha/v1
 {:tests &#91;{:id :system :focus-meta &#91;:system&#93;}
          {:id :unit}&#93;
  :plugins &#91;:kaocha.plugin/profiling
            :kaocha.plugin/cloverage&#93;}
</code></pre><p>If I run the tests again:</p><pre><code class="clojure">clj -M:dev:test --focus :system
Loading namespaces:  &#40;my-app.core.cfg my-app.core.env my-app.core.fib my-app.core&#41;
Test namespaces:  &#40;:system :unit&#41;
Instrumented my-app.core.cfg
Instrumented my-app.core.env
Instrumented my-app.core.fib
Instrumented my-app.core
Instrumented 4 namespaces in 0.4 seconds.
malli: instrumented 1 function vars
malli: dev-mode started
&#91;&#40;.&#41;&#93;
1 tests, 1 assertions, 0 failures.

Top 1 slowest kaocha.type/clojure.test &#40;0.02208 seconds, 97.0% of total time&#41;
  system
    0.02208 seconds average &#40;0.02208 seconds / 1 tests&#41;

Top 1 slowest kaocha.type/ns &#40;0.01914 seconds, 84.1% of total time&#41;
  my-app.core-test
    0.01914 seconds average &#40;0.01914 seconds / 1 tests&#41;

Top 1 slowest kaocha.type/var &#40;0.01619 seconds, 71.1% of total time&#41;
  my-app.core-test/system-test
    0.01619 seconds my&#95;app/core&#95;test.clj:9
Ran tests.
Writing HTML report to: /Users/loicblanchard/workspaces/clojure-proj-template/target/coverage/index.html

|-----------------+---------+---------|
|       Namespace | % Forms | % Lines |
|-----------------+---------+---------|
|     my-app.core |   44.44 |   62.50 |
| my-app.core.cfg |   69.57 |   74.07 |
| my-app.core.env |   11.11 |   44.44 |
| my-app.core.fib |  100.00 |  100.00 |
|-----------------+---------+---------|
|       ALL FILES |   55.26 |   70.59 |
|-----------------+---------+---------|
</code></pre><h3>Kaocha in terminal with options</h3><p>There are a bunch of options to enhance the development experience such as:</p><pre><code class="bash">clj -M:dev:test --watch --fail-fast
</code></pre><ul><li><code>watch</code> mode makes Kaocha rerun the tests on file save.</li><li><code>fail-fast</code> option makes Kaocha stop running the tests when it encounters a failing test</li></ul><p>These 2 options are very convenient for unit testing.</p><p>However, when a code base contains slower tests, if the slower tests are run first, the watch mode is not so convenient because it won‚Äôt provide instant feedback.</p><p>We saw that we can <code>focus</code> on tests with a specific metadata tag, we can also <code>skip</code> tests. Let‚Äôs pretend our <code>system</code> test is slow and we want to skip it to only run unit tests:</p><pre><code class="bash"> clj -M:dev:test --watch --fail-fast --skip-meta :system
</code></pre><p>Finally, I don‚Äôt want to use the <code>plugins</code> (profiling and code coverage) on watch mode as it clutter the space in the terminal, so I want to exclude them from the report.</p><p>We can actually create another kaocha config file for our watch mode.</p><p><code>tests-watch.edn</code>:</p><pre><code class="clojure">#kaocha/v1
 {:tests &#91;{:id :unit-watch :skip-meta &#91;:system&#93;}&#93; ;; ignore system tests
  :watch? true ;; watch mode on
  :fail-fast? true} ;; stop running on first failure
</code></pre><p>Notice that there is no plugins anymore, and watch mode and fail fast options are enabled. Also, the <code>system</code> tests are skipped.</p><pre><code class="clojure">clj -M:dev:test --config-file tests&#95;watch.edn
SLF4J&#40;I&#41;: Connected with provider of type &#91;org.slf4j.nop.NOPServiceProvider&#93;
malli: instrumented 1 function vars
malli: dev-mode started
&#91;&#40;.&#41;&#40;&#40;&#41;&#40;..&#41;&#40;..&#41;&#40;..&#41;&#41;&#93;
2 tests, 7 assertions, 0 failures.
</code></pre><p>We can now leave the terminal always on, change a file and save it and the tests will be rerun using all the options mentioned above.</p><h2>Documentation as unit tests: Rich Comment Tests</h2><p>Another approach to unit testing is to enhance the <code>comment</code> blocks to contain tests. This means that we don‚Äôt need a test file, we can just write our tests right below our functions and it serves as both documentation and unit tests.</p><p>Going back to our first example:</p><pre><code class="clojure">&#40;ns my-app.core.fib&#41;

&#40;defn fib
  &quot;Return the Fibonacci sequence with a lenght of `n`.&quot;
  &#91;n&#93;
  &#40;-&gt;&gt; &#40;iterate &#40;fn &#91;&#91;a b&#93;&#93; &#91;b &#40;+' a b&#41;&#93;&#41;
                &#91;0 1&#93;&#41;
       &#40;map first&#41;
       &#40;take n&#41;&#41;&#41;

&#94;:rct/test
&#40;comment
  &#40;fib 10&#41; ;=&gt; &#91;0 1 1 2 3 5 8 13 21 34&#93;
  &#40;fib 0&#41; ;=&gt; &#91;&#93;
  &#41;
</code></pre><p>The <code>comment</code> block showcases example of what the <code>fib</code> could return given some inputs and the values after <code>;=&gt;</code> are actually verified when the tests are run.</p><h3>RC Tests in the REPL</h3><p>We just need to evaluate <code>&#40;com.mjdowney.rich-comment-tests/run-ns-tests! &#42;ns&#42;&#41;</code> in the namespace we want to test:</p><pre><code class="clojure">cljÍûâmy-app.core-testÍûâ&gt;¬†
; Evaluating file: fib.clj
nil
cljÍûâmy-app.core.fibÍûâ&gt;¬†
&#40;com.mjdowney.rich-comment-tests/run-ns-tests! &#42;ns&#42;&#41;
; 
; Testing my-app.core.fib
; 
; Ran 1 tests containing 2 assertions.
; 0 failures, 0 errors.
{:test 1, :pass 2, :fail 0, :error 0}
</code></pre><h3>RC Tests in the terminal</h3><p>You might wonder how to run all the RC Tests of the project. Actually, we already did that, when we ran Kaocha unit tests in the terminal.</p><p>This is possible by wrapping the RC Tests in a deftest like so:</p><pre><code class="clojure">&#40;ns my-app.rc-test
  &quot;Rich Comment tests&quot;
  &#40;:require &#91;clojure.test :refer &#91;deftest testing&#93;&#93;
            &#91;com.mjdowney.rich-comment-tests.test-runner :as rctr&#93;&#41;&#41;

&#40;deftest &#94;rct rich-comment-tests
  &#40;testing &quot;all white box small tests&quot;
    &#40;rctr/run-tests-in-file-tree! :dirs #{&quot;src&quot;}&#41;&#41;&#41;
</code></pre><p>And if we want to run just the <code>rct</code> tests, we can focus on the metadata (see the metadata in the deftest above).</p><pre><code class="clojure">clj -M:dev:test --focus-meta :rct
</code></pre><p>It is possible to run the RC Tests without using Kaocha of course, refer to their doc for that.</p><h2>clojure.test vs RCT?</h2><p>I personally use a mix of both. When the function is not too complex and internal (not supposed to be called by the client), I would use RCT.</p><p>For system tests, which inevitably often involve side-effects, I have a dedicated test namespace. Using <code>fixture</code> is often handy and also the tests are way more verbose which would have polluted the src namespaces with a <code>comment</code> block.</p><p>In the short example I used in this article, the project tree is as follow:</p><pre><code class="bash">‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ config
‚îÇ   ‚îî‚îÄ‚îÄ env.edn
‚îú‚îÄ‚îÄ deps.edn
‚îú‚îÄ‚îÄ dev
‚îÇ   ‚îî‚îÄ‚îÄ user.clj
‚îú‚îÄ‚îÄ jib.edn
‚îú‚îÄ‚îÄ project.edn
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îî‚îÄ‚îÄ my&#95;app
‚îÇ       ‚îú‚îÄ‚îÄ core
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ cfg.clj
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ env.clj
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ fib.clj
‚îÇ       ‚îî‚îÄ‚îÄ core.clj
‚îú‚îÄ‚îÄ test
‚îÇ   ‚îî‚îÄ‚îÄ my&#95;app
‚îÇ       ‚îú‚îÄ‚îÄ core&#95;test.clj
‚îÇ       ‚îî‚îÄ‚îÄ rc&#95;test.clj
‚îú‚îÄ‚îÄ tests.edn
‚îî‚îÄ‚îÄ tests&#95;watch.edn
</code></pre><p><code>cfg.clj</code>, <code>env.clj</code> and <code>fib.clj</code> have RCT and <code>core&#95;test.clj</code> has regular deftest.</p><p>A rule of thumb could be: use regular deftest if the tests require at least one of the following:</p><ul><li>fixtures: start and tear down resources (db, kafka, entire system etc)</li><li>verbose setup (configs, logging etc)</li><li>side-effects (testing the entire system, load tests, stress tests etc)</li></ul><p>When the implementation is easy to test, using RCT is good for a combo doc+test.</p><h2>Data Validation and Generative testing</h2><p>There are 2 main libraries I personally used for data validation an generative testing: <a href='https://github.com/clojure/spec.alpha'>clojure/spec.alpha</a> and <a href='https://github.com/metosin/malli'>malli</a>. I will not explain in details how both work because that could be a whole article on its own. However, you can guess which one I used in my example project as you might have noticed the <code>instrumentation</code> logs when I ran the Kaocha tests: Malli.</p><h3>Malli: Data validation</h3><p>Here is the config namespace that is responsible to validate the env variables passed to our hypothetical app:</p><pre><code class="clojure">&#40;ns my-app.core.cfg
  &#40;:require &#91;malli.core :as m&#93;
            &#91;malli.registry :as mr&#93;
            &#91;malli.util :as mu&#93;&#41;&#41;

;; ---------- Schema Registry ----------

&#40;def domain-registry
  &quot;Registry for malli schemas.&quot;
  {::app
   &#91;:map {:closed true}
    &#91;:app/name :string&#93;
    &#91;:app/version :string&#93;&#93;
   ::fib
   &#91;:map {:closed true}
    &#91;:fib/length :int&#93;&#93;}&#41;

;; ---------- Validation ----------

&#40;mr/set-default-registry!
 &#40;mr/composite-registry
  &#40;m/default-schemas&#41;
  &#40;mu/schemas&#41;
  domain-registry&#41;&#41;

&#40;def cfg-sch
  &#91;:map {:closed true}
   &#91;:cfg/app ::app&#93;
   &#91;:cfg/fib ::fib&#93;&#93;&#41;

&#40;defn validate
  &quot;Validates the given `data` against the given `schema`.
   If the validation passes, returns the data.
   Else, returns the error data.&quot;
  &#91;data schema&#93;
  &#40;let &#91;validator &#40;m/validator schema&#41;&#93;
    &#40;if &#40;validator data&#41;
      data
      &#40;throw
       &#40;ex-info &quot;Invalid Configs Provided&quot;
                &#40;m/explain schema data&#41;&#41;&#41;&#41;&#41;&#41;

&#40;defn validate-cfg
  &#91;cfg&#93;
  &#40;validate cfg cfg-sch&#41;&#41;

&#94;:rct/test
&#40;comment
  &#40;def cfg #:cfg{:app #:app{:name &quot;my-app&quot;
                            :version &quot;1.0.0-RC1&quot;}
                 :fib #:fib{:length 10}}&#41;

  &#40;validate-cfg cfg&#41; ;=&gt;&gt; cfg
  &#40;validate-cfg &#40;assoc cfg :cfg/wrong 2&#41;&#41; ;throws=&gt;&gt; some?
  &#41;
</code></pre><p>Not going into too much details here but you can see that we define a <code>schema</code> that follows our data structure. In this case, my data structure I want to spec is my config map.</p><h3>Malli: Data Generation</h3><p>Let‚Äôs have a look at a simple example of a test of our system which randomly generates a length and verifies that the result is indeed a sequence of numbers with <code>length</code> element:</p><pre><code class="clojure">&#40;ns my-app.core-test
  &#40;:require &#91;clojure.test :refer &#91;deftest is testing&#93;&#93;
            &#91;malli.dev :as dev&#93;
            &#91;malli.dev.pretty :as pretty&#93;
            &#91;malli.generator :as mg&#93;
            &#91;my-app.core :as sut&#93;
            &#91;my-app.core.cfg :as cfg&#93;&#41;&#41;

&#40;dev/start! {:report &#40;pretty/reporter&#41;}&#41;

&#40;deftest &#94;:system system-test
  &#40;testing &quot;The Fib sequence is returned.&quot;
    &#40;is &#40;= &#91;0 1 1 2 3 5 8 13 21 34&#93;
           &#40;sut/system #:cfg{:app #:app{:name &quot;app&quot; :version &quot;1.0.0&quot;}
                             :fib #:fib{:length 10}}&#41;&#41;&#41;&#41;
  &#40;testing &quot;No matter the length of the sequence provided, the system returns the Fib sequence.&quot;
    &#40;let &#91;length &#40;mg/generate pos-int? {:size 10}&#41;
          cfg #:cfg{:app #:app{:name &quot;app&quot; :version &quot;1.0.0&quot;}
                    :fib #:fib{:length length}}
          rslt &#40;sut/system cfg&#41;&#93;
      &#40;is &#40;cfg/validate
           rslt
           &#91;:sequential {:min length :max length} :int&#93;&#41;&#41;&#41;&#41;&#41;
</code></pre><p>The second <code>testing</code> highlights both data generation (the <code>length</code>) and data validation (result must be a sequence of <code>int</code> with <code>length</code> elements).</p><p>The <code>dev/start!</code> starts malli instrumentation. It automatically detects functions which have malli specs and validate it. Let‚Äôs see what it does exactly in the next section.</p><h3>Malli: Instrumentation</h3><p>Earlier, we saw tests for the <code>core/system</code> functions. Here is the core namespace:</p><pre><code class="clojure">&#40;ns my-app.core
  &#40;:require &#91;my-app.core.cfg :as cfg&#93;
            &#91;my-app.core.env :as env&#93;
            &#91;my-app.core.fib :as fib&#93;&#41;&#41;

&#40;defn system
  {:malli/schema
   &#91;:=&gt; &#91;:cat cfg/cfg-sch&#93; &#91;:sequential :int&#93;&#93;}
  &#91;cfg&#93;
  &#40;let &#91;length &#40;-&gt; cfg :cfg/fib :fib/length&#41;&#93;
    &#40;fib/fib length&#41;&#41;&#41;

&#40;defn -main &#91;&amp; &#95;&#93;
  &#40;let &#91;cfg &#40;cfg/validate-cfg #:cfg{:app &#40;env/config&lt;-env :APP&#41;
                                    :fib &#40;env/config&lt;-env :FIB&#41;}&#41;&#93;
    &#40;system cfg&#41;&#41;&#41;
</code></pre><p>The <code>system</code> function is straight forward. It takes a config map and returns the fib sequence.</p><p>Note the metadata of that function:</p><pre><code class="clojure">{:malli/schema
   &#91;:=&gt; &#91;:cat cfg/cfg-sch&#93; &#91;:sequential :int&#93;&#93;}
</code></pre><p>The arrow <code>:=&gt;</code> means it is a function schema. So in this case, we expect a config as unique argument and we expect a sequence of int as returned value.</p><p>When we <code>instrument</code> our namespace, we tell malli to check the given argument and returned value and to throw an error if they do not respect the schema in the metadata. It is very convenient.</p><p>To enable the instrumentation, we call <code>malli.dev/start!</code> as you can see in the <code>core-test</code> namespace code snippet.</p><h3>When to use data validation/generation/instrumentation</h3><p>Clojure is a dynamically typed language, allowing us to write functions without being constrained by rigid type definitions. This flexibility encourages rapid development, experimentation, and iteration. Thus, it makes testing a bliss because we can easily mock function inputs or provide partial inputs.</p><p>However, if we start adding type check to all functions in all namespaces (in our case with malli metadata for instance), we introduce strict typing to our entire code base and therefore all the constraints that come with it.</p><p>Personally, I recommend adding validation for the entry point of the app only. For instance, if we develop a library, we will most likely have a top level namespace called <code>my-app.core</code> or <code>my-app.main</code> with the different functions our client can call. These functions are the ones we want to validate. All the internal logic, not supposed to be called by the clients, even though they can, do not need to be spec‚Äôed as we want to maintain the flexibility I mentioned earlier.</p><p>A second example could be that we develop an app that has a <code>-main</code> function that will be called to start our system. A system can be whatever our app needs to perform. It can start servers, connect to databases, perform batch jobs etc. Note that in that case the entry point of our program is the <code>-main</code> function. What we want to validate is that the proper params are passed to the system that our <code>-main</code> function will start. Going back to our Fib app example, our system is very simple, it just returns the Fib sequence given the length. The length is what need to be validated in our case as it is provided externally via env variable. That is why we saw that the system function had malli metadata. However, our internal function have tests but no spec to keep that dynamic language flexibility that Clojure offers.</p><p>Finally, note the distinction between <code>instrumentation</code>, that is used for development (the metadata with the function schemas) and data validation for production (call to <code>cfg/validate-cfg</code>). For overhead reasons, we don't want to instrument our functions in production, it is a development tool. However, we do want to have our system throws an error when wrong params are provided to our system, hence the call to <code>cfg/validate-cfg</code>.</p><h2>Load/stress/integration tests</h2><p>In functional programming, and especially in Clojure, it is important to avoid side effects (mutations, external factors, etc) as much as we can. Of course, we cannot avoid mutations as they are inevitable: start a server, connect to a database, IOs, update frontend web state and much more. What we can do is isolate these side effects so the rest of the code base remains pure and can enjoy the flexibility and thus predictable behavior.</p><h3>Mocking data</h3><p>Some might argue that we should never mock data. From my humble personal experience, this is impossible for complex apps. An app I worked on consumes messages from different kafka topics, does write/read from a datomic database, makes http calls to multiple remote servers and produces messages to several kafka topics. So if I don‚Äôt mock anything, I need to have several remote http servers in a test cluster just for testing. I need to have a real datomic database with production-like data. I need all the other apps that will produce kafka messages that my consumers will process. In other words, it is not possible.</p><p>We can mock functions using <a href='https://clojuredocs.org/clojure.core/with-redefs'>with-redefs</a> which is very convenient for testing. Using the clojure.test <a href='https://clojuredocs.org/clojure.test/use-fixtures'>use-fixtures</a> is also great to start and tear down services after the tests are done.</p><h3>Integration tests</h3><p>I mentioned above, an app using datomic and kafka for instance. In my integration tests, I want to be able to produce kafka messages and I want to interact with an actual datomic db to ensure proper behavior of my app. The common approach for this is to use <code>embedded</code> versions of these services. Our test fixtures can start/delete an embedded datomic database and start/stop kafka consumers/producers as well.</p><p>What about the http calls? We can <code>with-redefs</code> those to return some valid but randomly generated values. Integration tests aim at ensuring that all components of our app work together as expected and embedded versions of external services and redefinitions of vars can make the tests predictable and suitable for CI.</p><p>I have not touch on running tests in the CI, but integration tests should be run in the CI and if all services are embedded, there should be no difficulty in setting up a pipeline.</p><h3>Load/stress tests</h3><p>To be sure an app performs well under heavy load, embedded services won‚Äôt work as they are limited in terms of performance, parallel processing etc. In our example above, If I want to start lots of kafka consumers and to use a big datomic transactor to cater lots of transactions, embedded datomic and embedded kafka won‚Äôt suffice. So I have to run a datomic transactor on my machine (maybe I want the DB to be pre-populated with millions or entities as well) and I will need to run kafka on my machine as well (maybe using confluent <a href='https://github.com/confluentinc/cp-all-in-one'>cp-all-in-one</a> container setup). Let‚Äôs get fancy, and also run prometheus/grafana to monitor the performance of the stress tests.</p><p>Your intuition is correct, it would be a nightmare for each developer of the project to setup all services. One solution is to containerized all these services. a datomic transactor can be run in docker, confluent provides a docker-compose to run kafka zookeeper, broker, control center etc, prometheus scrapper can be run in a container as well as grafana. So providing docker-compose files in our repo so each developer can just run <code>docker-compose up -d</code> to start all necessary services is the solution I recommend.</p><p>Note that I do not containerized my clojure app so I do not have to change anything in my workflow. I deal with load/stress tests the same way I deal with my unit tests. I just start the services in the containers and my Clojure REPL as per usual.</p><p>This setup is not the only solution to load/stress tests but it is the one I successfully implemented in my project and it really helps us being efficient.</p><h2>Conclusion</h2><p>I highlighted some common testing tools and methods that the Clojure community use and I explained how I personally incorporated these tools and methods to my projects. Tools are common to everybody, but how we use them is considered opinionated and will differ depending on the projects and team decision.</p><p>If you are starting your journey as a Clojure developer, I hope you can appreciate the quality of open-source testing libraries we have access to. Also, please remember that keeping things pure is the key to easy testing and debugging; a luxury not so common in the programming world. Inevitably, you will need to deal with side effects but isolate them as much as you can to make your code robust and your tests straight forward.</p><p>Finally, there are some tools I didn‚Äôt mention to keep things short so feel free to explore what the Clojure community has to offer. The last advice I would give is to not try to use too many tools or only the shiny new ones you might find. Keep things simple and evaluate if a library is worth being added to your deps.</p>]]></content:encoded></item><item><title>Time as a value with Tick</title><link>https://www.loicblanchard.me/blog/tick</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/tick</guid><pubDate>Sat, 20 Apr 2024 08:16:25 +0000</pubDate><description>
Illustrate date and time concepts in programming using the Clojure Tick library: timestamp, date-time, offset, zone, instant, inst, UTC, DST, duration, period etc.
</description><content:encoded><![CDATA[<h2>Introduction</h2><p>It is always very confusing to deal with time in programming. In fact there are so many time representations, for legacy reasons, that sticking to one is not possible as our dependencies, databases or even programming languages might use different ways of representing time!</p><p>You might have asked yourself the following questions:</p><ul><li>Why so many time formats? <code>timestamp</code>, <code>date-time</code>, <code>offset-date-time</code>, <code>zoned-date-time</code>, <code>instant</code>, <code>inst</code>?</li><li>What is <code>UTC</code>, <code>DST</code>?</li><li>why use Java <code>Instant</code> instead of Java <code>Date</code>?</li><li>Why not only deal with <code>timestamp</code>?</li><li>How to go from one time representation to the other without getting lost?</li><li>What is the difference between a <code>duration</code> and a <code>period</code>?</li></ul><p>This article will answer these questions and will illustrate the answers with Clojure code snippets using the <code>juxt/tick</code> library.</p><h2>What is <code>Tick</code>?</h2><p><a href='https://github.com/juxt/tick'>juxt/tick</a> is an excellent open-source <strong>Clojure</strong> library to deal with <code>date</code> and <code>time</code> as values. The <a href='https://juxt.github.io/tick/'>documentation</a> is of very good quality as well.</p><h2>Time since epoch (timestamp)</h2><p>The <code>time since epoch</code>, or <code>timestamp</code>, is a way of measuring time by counting the number of time units that have elapsed since a specific point in time, called the <strong>epoch</strong>. It is often represented in either milliseconds or seconds, depending on the level of precision required for a particular application.</p><p>So basically, it is just an <code>int</code> such as <code>1705752000000</code></p><p>The obvious advantage is the universal simplicity of representing time. The disadvantage is the human readability. So we need to find a more human-friendly representation of time.</p><h2>Local time</h2><p><em>Alice is having some fish and chips for her lunch in the UK. She checks her clock on the wall and it shows 12pm. She checks her calendar and it shows the day is January the 20th.</em></p><p>The local time is the time in a specific time zone, usually represented using a date and time-of-day without any time zone information. In java it is called <code>java.time.LocalDateTime</code>. However, <code>tick</code> mentioned that when you asked someone the time, it is always going to be "local", so they prefer to call it <code>date-time</code> as the local part is implicit.</p><p>So if we ask Alice for the time and date, she will reply:</p><pre><code class="clojure">&#40;-&gt; &#40;t/time &quot;12:00&quot;&#41;
    &#40;t/on &quot;2024-01-20&quot;&#41;&#41;
;=&gt; #time/date-time &quot;2024-01-20T12:00&quot;
</code></pre><p><em>At the same time and date Alice is having lunch in London, Bob is having some fish soup for dinner in his Singapore's nearby food court. He checked the clock on the wall and reads 8pm.</em></p><p>So if we ask Bob for the time, he will reply that it is 8pm. So we can see that the local time is indeed local as Bob and Alice have different times.</p><p>The question is: how to have a common time representation for Bob and Alice?</p><h2>offset-date-time</h2><p>One of the difference between Bob and Alice times is due to the Coordinated Universal Time (<strong>UTC</strong>). The UTC offset is the difference between the local time and the UTC time, and it is usually represented using a plus or minus sign followed by the number of hours ahead or behind UTC</p><p>The United Kingdom is located on the prime meridian, which is the reference line for measuring longitude and the basis for the UTC time standard. Therefore, the local time in the UK is always the same as UTC time, and the time zone offset is <code>UTC+0</code> (also called <code>Z</code>). Alice is on the prime meridian, therefore the time she sees is the UTC time, the universal time reference.</p><p>As you go east, the difference with UTC increase. For example, Singapore is located at approximately 103.8 degrees east longitude, which means that it is eight hours ahead of UTC, and its time zone offset is <code>UTC+8</code>. That is why Bob is 8 hours ahead of Alice (8 hours in the "future")</p><p>As you go west, the difference with UTC decrease. For example, New York City is located at approximately 74 degrees west longitude, which means that it is four hours behind UTC during standard time, and its time zone offset is <code>UTC-4</code> (4 hours behind - 4 hours in the "past").</p><p>So, going back to our example, Bob is 8 hours ahead (in the "future") of Alice as we can see via the <code>UTC+8</code>:</p><pre><code class="clojure">;; Alice time
&#40;-&gt; &#40;t/time &quot;12:00&quot;&#41;
    &#40;t/on &quot;2024-01-20&quot;&#41;
    &#40;t/offset-by 0&#41;&#41;
;=&gt; #time/offset-date-time &quot;2024-01-20T12:00Z&quot;

;; Bob time
&#40;-&gt; &#40;t/time &quot;12:00&quot;&#41;
    &#40;t/on &quot;2024-01-20&quot;&#41;
    &#40;t/offset-by 8&#41;&#41;
;=&gt; #time/offset-date-time &quot;2024-01-20T12:00+08:00&quot;
</code></pre><p>We added the offset to our time representation, note the tick name for that representation: <code>offset-date-time</code>. In java, it is called <code>java.time.OffsetDateTime</code>. We can see for Bob's time a <code>+08:00</code>. This represents The Coordinated Universal Time (<strong>UTC</strong>) offset.</p><p>So we could assume that the UTC offset remains the same within the same <strong>zone</strong> (country or region), but it is not the case. Let's see why in the next section.</p><h2>zoned-date-time</h2><p>So far we have the following components to define a time:</p><ul><li>date</li><li>time</li><li>UTC offset</li></ul><p>However, counter-intuitively, the UTC offset for Alice is not the same all year long. Sometimes it is <code>UTC+0</code> (<code>Z</code>) in winter (as we saw earlier) but sometimes it is <code>UTC+1</code> in summer.</p><p>Let me prove it to you:</p><pre><code class="clojure">;; time for Alice in winter
&#40;-&gt; &#40;t/time &quot;12:00&quot;&#41;
    &#40;t/on &quot;2024-01-20&quot;&#41; ;; January - a winter month
    &#40;t/in &quot;Europe/London&quot;&#41;
    &#40;t/offset-date-time&#41;&#41;
;=&gt; #time/offset-date-time &quot;2024-01-20T12:00Z&quot;

;; time for Alice in summer
&#40;-&gt; &#40;t/time &quot;12:00&quot;&#41;
    &#40;t/on &quot;2024-08-20&quot;&#41; ;; August - a summer month
    &#40;t/in &quot;Europe/London&quot;&#41;
    &#40;t/offset-date-time&#41;&#41;
;=&gt; #time/offset-date-time &quot;2024-08-20T12:00+01:00&quot;
</code></pre><p>This UTC offset difference is due to the Daylight Saving Time (<strong>DST</strong>).</p><p>Daylight Saving Time (DST) is a system of adjusting the clock in order to make better use of daylight during the summer months by setting the clock forward by one hour in the spring and setting it back by one hour in the fall. This way, Alice can enjoy more of the sunlight in summer since the days are "longer" (more sunlight duration) while keeping her same working hours!</p><p>It is important to note that not all countries implement DSL. Some countries do not use DSL because they don't need. That is the case of Singapore. In Singapore, the sunset/sunrise is almost happening at the same time everyday so technically, there is no Winter/Summer. Some country chose not to use it. That's the case of Japan for instance. Japan could benefit from the DSL but chose not to implement it for diverse reasons.</p><p>So we can conclude that a UTC offset is not representative of a Zone because some country might implement DST and other not. Also, for the country implementing DST, their UTC is therefore not fix throughout the year. Thus, we need another parameter to fully define a time: the <strong>Zone</strong>:</p><pre><code class="clojure">&#40;-&gt; &#40;t/time &quot;12:00&quot;&#41;
    &#40;t/on &quot;2024-01-20&quot;&#41; ;; January - a winter month
    &#40;t/in &quot;Europe/London&quot;&#41;&#41;
;=&gt; #time/zoned-date-time &quot;2024-01-20T12:00Z&#91;Europe/London&#93;&quot;
</code></pre><p>You can notice that it is the same code as before but I remove the conversion to an <code>offset-date-time</code>. Indeed, Adding the zone like in <code>&#40;t/in &quot;Europe/London&quot;&#41;</code> is already considering the <strong>Zone</strong> obviously (and therefore the  <strong>UTC</strong>) thus creating a <code>zoned-date-time</code>.</p><p>A <code>#time/zoned-date-time</code> in Java is called a <code>java.time.ZonedDateTime</code>.</p><p>So we now have a complete way to describe the time:</p><ul><li>a date</li><li>a time</li><li>a zone (that includes the location and the UTC encapsulating the DST)</li></ul><p>So the time for Bob is:</p><pre><code class="clojure">&#40;-&gt; &#40;t/time &quot;12:00&quot;&#41;
    &#40;t/on &quot;2024-01-20&quot;&#41;
    &#40;t/in &quot;Asia/Singapore&quot;&#41;&#41;
;=&gt; #time/zoned-date-time &quot;2024-01-20T12:00+08:00&#91;Asia/Singapore&#93;&quot;
</code></pre><p>So to recap:</p><ul><li>the <strong>Zone</strong> <code>Asia/Singapore</code> always has the same <strong>UTC</strong> all year long because no <strong>DST</strong></li><li>the <strong>Zone</strong> <code>Europe/London</code> has a different <strong>UTC</strong> in summer and winter</li><li>thus Bob is ahead of Alice by 8 hours during winter and Bob is ahead of Alice by 7 hours during summer.</li><li>This is due by the fact that the UK implements <strong>DST</strong> which makes its own <strong>UTC</strong> throughout the year.</li></ul><p>So a <strong>Zone</strong> encapsulates the notion of <strong>UTC</strong> and <strong>DST</strong>.</p><h2>instant</h2><p>You might thought we were done here but actually the recommended time representation would be an <code>instant</code>. In java, it is called <code>java.time.Instant</code>. Why do we want to use instant is actually to avoid confusion. When you store a time in your DB, or when you want to add 10 days to this time, you actually don't want to deal with time zone. In programming, we always want to have a solution as simple as possible. Remember the very first time representation I mentioned? The <strong>time since epoch</strong>. The <code>epoch</code> in the prime meridian (<code>UTC+0</code>) is the same for everybody. So the time since epoch (to current UTC+0 time) in ms is a universal way of representing the time.</p><pre><code class="clojure">;; instant time for Alice
&#40;-&gt; &#40;t/time &quot;12:00&quot;&#41;
    &#40;t/on &quot;2024-01-20&quot;&#41;
    &#40;t/in &quot;Europe/London&quot;&#41;
    &#40;t/instant&#41;&#41;
;=&gt; #time/instant &quot;2024-01-20T12:00:00Z&quot;

;; instant time for Bob
&#40;-&gt; &#40;t/time &quot;20:00&quot;&#41;
    &#40;t/on &quot;2024-01-20&quot;&#41;
    &#40;t/in &quot;Asia/Singapore&quot;&#41;
    &#40;t/instant&#41;&#41;
;=&gt; #time/instant &quot;2024-01-20T12:00:00Z&quot;
</code></pre><p>We can see in the example above, that since Singapore is 8 hours ahead of London, 12pm in London and 8pm in Singapore are indeed the same <code>instant</code>.</p><p>The <code>instant</code> is the human-friendly time representation of the timestamp (time since epoch). You can then store that format in your DB or do operation on it such as adding/substituting duration or period to it (more on this later).</p><p>The <code>epoch</code> in time-since-epoch is equivalent to #time/instant "1970-01-01T00:00:00Z":</p><pre><code class="clojure">&#40;t/epoch&#41;
;=&gt; #time/instant &quot;1970-01-01T00:00:00Z&quot;
</code></pre><h2>Alice and Bob don't care about instants</h2><p>That is correct, if we have a web page, we want Alice to see the time in London time and Bob the time in Singapore time. This is easy to do. we can derive the <code>zoned-date-time</code> from an <code>instant</code> since we know the zone of Bob and Alice:</p><pre><code class="clojure">;; in Alice's browser
&#40;t/format &#40;t/formatter &quot;yyyy-MM-dd HH:mm:ss&quot;&#41;
          &#40;t/in #time/instant &quot;2024-01-20T12:00:00Z&quot; &quot;Europe/London&quot;&#41;&#41;
&quot;2024-01-20 12:00:00&quot;

;; in Bob's browser
&#40;t/format &#40;t/formatter &quot;yyyy-MM-dd HH:mm:ss&quot;&#41;
          &#40;t/in #time/instant &quot;2024-01-20T12:00:00Z&quot; &quot;Asia/Singapore&quot;&#41;&#41;
&quot;2024-01-20 20:00:00&quot;
</code></pre><h2>inst</h2><p>Last time format I promise. As a clojure developer, you might often see <code>inst</code>. It is <strong>different</strong> from <code>instant</code>. In java <code>inst</code> is called <code>java.util.Date</code>. The <code>java.util.Date</code> class is an old and flawed class that was replaced by the Java 8 time API, and it should be avoided when possible.</p><p>However, some libraries might require you to pass <code>inst</code> instead of <code>instant</code> still, and it is easy to convert between the two using the Tick library:</p><pre><code class="clojure">&#40;t/inst #time/instant &quot;2024-01-20T04:00:00Z&quot;&#41;
;=&gt; #inst &quot;2024-01-20T04:00:00.000-00:00&quot;
</code></pre><p>What about the other way around?</p><pre><code class="clojure">&#40;t/instant #inst &quot;2024-01-20T04:00:00.000-00:00&quot;&#41;
;=&gt; #time/instant &quot;2024-01-20T04:00:00Z&quot;
</code></pre><h2>All theses time formats are confusing</h2><p>Just remember these key points:</p><ul><li>to store or do operations on time, use <code>instant</code> (java.time.Instant)</li><li>to represent time locally for users, convert your instant to <code>zoned-date-time</code> (java.time.ZonedDateTime)</li><li>to have a human readable format aka browser, parse your <code>zoned-date-time</code> using string formatter</li><li>if a third party lib needs other format, use tick intuitive conversion functions (t/inst, t/instant etc)</li></ul><h2>Duration vs Period</h2><p>We now know that we need to use <code>instant</code> to perform operations on time. However, sometimes we use <code>duration</code> and sometimes we use <code>period</code>:</p><pre><code class="clojure">&#40;t/new-duration 10 :seconds&#41;
;=&gt; #time/duration &quot;PT10S&quot;

&#40;t/new-period 10 :weeks&#41;
;=&gt; #time/period &quot;P70D&quot;
</code></pre><p>They are not interchangeable:</p><pre><code class="clojure">&#40;t/new-period 10 :seconds&#41;
; Execution error &#40;IllegalArgumentException&#41; at tick.core/new-period &#40;core.cljc:649&#41;.
; No matching clause: :seconds
</code></pre><p>So what is the difference? I will give you a clue:</p><ul><li>all units from <code>nanosecond</code> to <code>day</code> (included) are <code>durations</code></li><li>all units from <code>day</code> such as a <code>week</code> for instance are a <code>period</code>.</li></ul><p>There is one unit that can be both a <code>duration</code> and a <code>period</code>: a <code>day</code>:</p><pre><code class="clojure">;; day as duration
&#40;t/new-duration 10 :days&#41;
#time/duration &quot;PT240H&quot;

;; day as period
&#40;t/new-period 10 :days&#41;
#time/period &quot;P10D&quot;
</code></pre><p>Therefore, a simple definition could be:</p><ul><li>a <code>duration</code> measures an amount of time using time-based values (seconds, nanoseconds).</li><li>a <code>period</code> uses date-based (we can also calendar-based) values (years, months, days)</li><li>a <code>day</code> can be both <code>duration</code> and <code>period</code>: a duration of one day is exactly 24 hours long but a period of one day, when considering the calendar, may vary.</li></ul><p>First, here is how you would add a day as duration or as a period to the proper format:</p><pre><code class="clojure">;; time-based so use duration
&#40;-&gt; &#40;t/time &quot;10:00&quot;&#41;
    &#40;t/&gt;&gt; &#40;t/new-duration 4 :hours&#41;&#41;&#41;
;=&gt; #time/time &quot;14:00&quot;

;; date-based so use period
&#40;-&gt; &#40;t/date &quot;2024-04-01&quot;&#41;
    &#40;t/&gt;&gt; &#40;t/new-period 1 :days&#41;&#41;&#41;
;=&gt; #time/date &quot;2024-04-02&quot;
</code></pre><p>Now, let me prove to you that we need to be careful to chose the right format for a day. In London, at 1am on the last Sunday of March, the clocks go forward 1 hour (DST increase by one because we enter summer months). So in 2024, at 1am, on March 31st, clocks go forward 1 hour.</p><pre><code class="clojure">;; we add a period of 1 day
&#40;-&gt; &#40;t/time &quot;08:00&quot;&#41;
    &#40;t/on &quot;2024-03-30&quot;&#41;
    &#40;t/in &quot;Europe/London&quot;&#41;
    &#40;t/&gt;&gt; &#40;t/new-period 1 :days&#41;&#41;&#41;
#time/zoned-date-time &quot;2024-03-31T08:00+01:00&#91;Europe/London&#93;&quot;

;; we add a duration of 1 day
&#40;-&gt; &#40;t/time &quot;08:00&quot;&#41;
    &#40;t/on &quot;2024-03-30&quot;&#41;
    &#40;t/in &quot;Europe/London&quot;&#41;
    &#40;t/&gt;&gt; &#40;t/new-duration 1 :days&#41;&#41;&#41;
#time/zoned-date-time &quot;2024-03-31T09:00+01:00&#91;Europe/London&#93;&quot;
</code></pre><p>We can see that since in this specific DST update to summer month, the day 03/31 "gained" an hour so it has a <code>duration</code> of 25 hours, therefore our new time is <code>09:00</code>. However, the <code>period</code> taking into consideration the date in a calendar system, does not see a day as 24 hours (time-base) but as calendar unit (date-based) and therefore the new time is still <code>08:00</code>.</p><h2>Conclusion</h2><p>A <strong>Zone</strong> encapsulates the notion of <strong>UTC</strong> and <strong>DST</strong>.</p><p>The <strong>time since epoch</strong> is the universal <em>computer-friendly</em> of representing time whereas the <strong>Instant</strong> is the universal <em>human-friendly</em> of representing time.</p><p>A <code>duration</code> measures an amount of time using time-based values whereas a <code>period</code> uses date-based (calendar) values.</p><p>Finally, for Clojure developers, I highly recommend using <code>juxt/tick</code> as it allows us to handle time efficiently (conversion, operations) and elegantly (readable, as values) and I use it in several of my projects. It is also of course possible to do interop with the <code>java.time.Instant</code> class directly if you prefer.</p>]]></content:encoded></item><item><title>Fun-Map applied to flybot.sg</title><link>https://www.loicblanchard.me/blog/fun-map-applied-to-flybot</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/fun-map-applied-to-flybot</guid><pubDate>Mon, 08 May 2023 08:16:25 +0000</pubDate><description>
how we leverage `fun-map` to create different systems in the website flybot.sg: `prod-system`, `dev-system`, `test-system` and `figwheel-system`.
</description><content:encoded><![CDATA[<h2>Prerequisites</h2><p>If you are not familiar with <a href='https://github.com/robertluo/fun-map'>fun-map</a>, please refer to the doc <a href='https://www.loicblanchard.me/blog/fun-map'>Fun-Map: a solution to deps injection in Clojure</a>.</p><h2>Goal</h2><p>In this document, I will show you how we leverage <code>fun-map</code> to create different systems in the website <a href='https://www.flybot.sg/'>flybot.sg</a>: <code>prod-system</code>, <code>dev-system</code>, <code>test-system</code> and <code>figwheel-system</code>.</p><h2>Prod System</h2><p>In our backend, we use <code>life-cycle-map</code> to manage the life cycle of all our stateful components.</p><h3>Describe the system</h3><p>Here is the system we currently have for production:</p><pre><code class="clojure">&#40;defn system
  &#91;{:keys &#91;http-port db-uri google-creds oauth2-callback client-root-path&#93;
    :or {client-root-path &quot;/&quot;}}&#93;
  &#40;life-cycle-map
   {:db-uri         db-uri
    :db-conn        &#40;fnk &#91;db-uri&#93;
                         &#40;let &#91;conn &#40;d/get-conn db-uri db/initial-datalevin-schema&#41;&#93;
                           &#40;load-initial-data conn data/init-data&#41;
                           &#40;closeable
                            {:conn conn}
                            #&#40;d/close conn&#41;&#41;&#41;&#41;
    :oauth2-config  &#40;let &#91;{:keys &#91;client-id client-secret&#93;} google-creds&#93;
                      &#40;-&gt; config/oauth2-default-config
                          &#40;assoc-in &#91;:google :client-id&#93; client-id&#41;
                          &#40;assoc-in &#91;:google :client-secret&#93; client-secret&#41;
                          &#40;assoc-in &#91;:google :redirect-uri&#93; oauth2-callback&#41;
                          &#40;assoc-in &#91;:google :client-root-path&#93; client-root-path&#41;&#41;&#41;
    :session-store  &#40;memory-store&#41;
    :injectors      &#40;fnk &#91;db-conn&#93;
                         &#91;&#40;fn &#91;&#93; {:db &#40;d/db &#40;:conn db-conn&#41;&#41;}&#41;&#93;&#41;
    :executors      &#40;fnk &#91;db-conn&#93;
                         &#91;&#40;handler/mk-executors &#40;:conn db-conn&#41;&#41;&#93;&#41;
    :saturn-handler handler/saturn-handler
    :ring-handler   &#40;fnk &#91;injectors saturn-handler executors&#93;
                         &#40;handler/mk-ring-handler injectors saturn-handler executors&#41;&#41;
    :reitit-router  &#40;fnk &#91;ring-handler oauth2-config session-store&#93;
                         &#40;handler/app-routes ring-handler oauth2-config session-store&#41;&#41;
    :http-server    &#40;fnk &#91;http-port reitit-router&#93;
                         &#40;let &#91;svr &#40;http/start-server
                                    reitit-router
                                    {:port http-port}&#41;&#93;
                           &#40;closeable
                            svr
                            #&#40;.close svr&#41;&#41;&#41;&#41;}&#41;&#41;

&#40;def prod-system
  &quot;The prod system starts a server on port 8123.
   It does not load any init-data on touch and it does not delete any data on halt!.
   You can use it in your local environment as well.&quot;
  &#40;let &#91;prod-cfg &#40;config/system-config :prod&#41;&#93;
    &#40;system prod-cfg&#41;&#41;&#41;
</code></pre><p>At a glance, we can easily understand the dependency injections flow of the app.</p><p>If we were to represent these deps as a simple graph, we could have:</p><pre><code class="bash">life-cycle-map
‚îú‚îÄ‚îÄ :db-conn &#40;closeable&#41;
‚îú‚îÄ‚îÄ :oauth2-config
‚îú‚îÄ‚îÄ :session-store
‚îú‚îÄ‚îÄ :injectors
‚îÇ   ‚îî‚îÄ‚îÄ :db-conn
‚îú‚îÄ‚îÄ :executors
‚îÇ   ‚îî‚îÄ‚îÄ :db-conn
‚îú‚îÄ‚îÄ :saturn-handler
‚îú‚îÄ‚îÄ :ring-handler
‚îÇ   ‚îú‚îÄ‚îÄ :injectors
‚îÇ   ‚îú‚îÄ‚îÄ :executors
‚îÇ   ‚îú‚îÄ‚îÄ :saturn-handler
‚îú‚îÄ‚îÄ :reitit-router
‚îÇ   ‚îú‚îÄ‚îÄ :ring-handler
‚îÇ   ‚îú‚îÄ‚îÄ :oauth2-config
‚îÇ   ‚îî‚îÄ‚îÄ :session-store
‚îî‚îÄ‚îÄ :http-server &#40;closeable&#41;
    ‚îú‚îÄ‚îÄ :http-port
    ‚îú‚îÄ‚îÄ :reitit-router
</code></pre><p>The function <code>prod-system</code> just fetches some env variables with the necessary configs to start the system.</p><h3>Run the system</h3><p>We can then easily start the system via the fun-map function <code>touch</code> :</p><pre><code class="clojure">cljÍûâclj.flybot.coreÍûâ&gt; 
&#40;touch prod-system&#41;
{:ring-handler #function&#91;clj.flybot.handler/mk-ring-handler/fn--37646&#93;,
 :executors &#91;#function&#91;clj.flybot.handler/mk-executors/fn--37616&#93;&#93;,
 :injectors &#91;#function&#91;clj.flybot.core/system/fn--38015/fn--38016&#93;&#93;,
 :http-server
 #object&#91;aleph.netty$start&#95;server$reify&#95;&#95;11448 0x389add75 &quot;AlephServer&#91;channel:&#91;id: 0xd98ed2db, L:/0.0.0.0:8123&#93;, transport::nio&#93;&quot;&#93;,
 :reitit-router #function&#91;clojure.lang.AFunction/1&#93;,
 :http-port 8123,
 :db-uri &quot;datalevin/prod/flybotdb&quot;,
 :oauth2-config
 {:google
  {:scopes &#91;&quot;https://www.googleapis.com/auth/userinfo.email&quot; &quot;https://www.googleapis.com/auth/userinfo.profile&quot;&#93;,
   :redirect-uri &quot;https://v2.fybot.sg/oauth/google/callback&quot;,
   :client-id &quot;client-id&quot;,
   :access-token-uri &quot;https://oauth2.googleapis.com/token&quot;,
   :authorize-uri &quot;https://accounts.google.com/o/oauth2/auth&quot;,
   :launch-uri &quot;/oauth/google/login&quot;,
   :client-secret &quot;client-secret&quot;,
   :project-id &quot;flybot-website&quot;,
   :landing-uri &quot;/oauth/google/success&quot;}},
 :session-store
 #object&#91;ring.middleware.session.memory.MemoryStore 0x1afb7eac &quot;ring.middleware.session.memory.MemoryStore@1afb7eac&quot;&#93;,
 :saturn-handler #function&#91;clj.flybot.handler/saturn-handler&#93;,
 :db-conn
 {:conn
  #&lt;Atom@1ada44a1: 
    {:store #object&#91;datalevin.storage.Store 0x4578bf30 &quot;datalevin.storage.Store@4578bf30&quot;&#93;,
     :eavt #{},
     :avet #{},
     :veat #{},
     :max-eid 73,
     :max-tx 5,
     :hash nil}&gt;}}
</code></pre><h2>Dev System</h2><p>The <code>system</code> described above can easily be adapted to be used for development purposes.</p><p>Actually, the only differences between the prod and dev systems are the following:</p><ul><li>The configs (db uri, oauth2 callback)</li><li>How to shutdown the db system (<code>dev</code> clears the db, <code>prod</code> retains db data)</li></ul><p>Thus, we just have to assoc a new db component to the <code>system</code> and read some dev configs instead of getting prod env variables:</p><pre><code class="clojure">&#40;defn db-conn-system
  &quot;On touch: empty the db and get conn.
   On halt!: close conn and empty the db.&quot;
  &#91;init-data&#93;
  &#40;fnk &#91;db-uri&#93;
       &#40;let &#91;conn &#40;d/get-conn db-uri&#41;
             &#95;    &#40;d/clear conn&#41;
             conn &#40;d/get-conn db-uri db/initial-datalevin-schema&#41;&#93;
         &#40;load-initial-data conn init-data&#41;
         &#40;closeable
          {:conn conn}
          #&#40;d/clear conn&#41;&#41;&#41;&#41;&#41;

&#40;def dev-system
  &quot;The dev system starts a server on port 8123.
   It loads some real data sample. The data is deleted when the system halt!.
   It is convenient if you want to see your backend changes in action in the UI.&quot;
  &#40;-&gt; &#40;system &#40;config/system-config :dev&#41;&#41;
      &#40;assoc :db-conn &#40;db-conn-system data/init-data&#41;&#41;&#41;&#41;
</code></pre><p>The important thing to remember is that all the modifications to the system must be done before starting the system (via <code>touch</code>). If some modifications need to be made to the running system:</p><ol><li>Shutdown the system (via <code>halt!</code>)</li><li>Update the system logic</li><li>Start the newly modified system (via <code>touch</code>)</li></ol><h2>Test system</h2><p>Naturally, the fun-map system also plays well with testing.</p><p>Same process as for dev and prod, we just need to adapt the system a bit to run our tests.</p><p>The tests requirement are:</p><ul><li>Dedicated db uri and specific data sample to work with</li><li>Ignore Oauth2.0.</li></ul><p>So same as for dev, we just read dedicated test configs and assoc a test db system to the default system:</p><pre><code class="clojure">&#40;defn test-system
  &#91;&#93;
  &#40;-&gt; &#40;config/system-config :test&#41;
      sys/system
      &#40;dissoc :oauth2-config&#41;
      &#40;assoc :db-conn &#40;sys/db-conn-system test-data&#41;&#41;&#41;&#41;
</code></pre><p>This works well with the clojure.test fixtures:</p><pre><code class="clojure">;; atom required to re-evalualte &#40;test-system&#41; because of fixture `:each`
&#40;def a-test-system &#40;atom nil&#41;&#41;

&#40;defn system-fixture &#91;f&#93;
  &#40;reset! a-test-system &#40;test-system&#41;&#41;
  &#40;touch @a-test-system&#41;
  &#40;f&#41;
  &#40;halt! @a-test-system&#41;&#41;

&#40;use-fixtures :each system-fixture&#41;
</code></pre><h2>Figwheel system</h2><p>It is possible to <a href='https://figwheel.org/docs/ring-handler.html'>provide a ring-handler</a> to figwheel configs which will be passed to a server figwheel starts for us.</p><p>We just need to specify a ring-handler in <code>figwheel-main.edn</code> like so:</p><pre><code class="clojure">{:ring-handler flybot.server.systems/figwheel-handler
 :auto-testing true}
</code></pre><p>Our system does have a ring-handler we can supply to figwheel, it is called <code>reitit-router</code> in our system (it returns a ring-handler).</p><p>Since figwheel starts the server, we do not need the aleph server dependency in our system anymore, se we can dissoc it from the system.</p><p>So here is the <code>figwheel-system</code> :</p><pre><code class="clojure">&#40;def figwheel-system
  &quot;Figwheel automatically touches the system via the figwheel-main.edn on port 9500.
   Figwheel just needs a handler and starts its own server hence we dissoc the http-server.
   If some changes are made in one of the backend component &#40;such as handler for instance&#41;,
   you can halt!, reload ns and touch again the system.&quot;
  &#40;-&gt; &#40;config/system-config :figwheel&#41;
      system
      &#40;assoc :db-conn &#40;db-conn-system data/init-data&#41;&#41;
      &#40;dissoc :http-port :http-server&#41;&#41;&#41;

&#40;def figwheel-handler
  &quot;Provided to figwheel-main.edn.
   Figwheel uses this handler to starts a server on port 9500.
   Since the system is touched on namespace load, you need to have
   the flag :figwheel? set to true in the config.&quot;
  &#40;when &#40;:figwheel? CONFIG&#41;
    &#40;-&gt; figwheel-system
        touch
        :reitit-router&#41;&#41;&#41;
</code></pre><p>The <code>figheel-handler</code> is the value of the key <code>:reitit-router</code> of our running system.</p><p>So the system is started first via <code>touch</code> and its handler is provided to the servers figwheel starts that will be running while we work on our frontend.</p>]]></content:encoded></item><item><title>Lasagna-pull applied to flybot.sg</title><link>https://www.loicblanchard.me/blog/lasagna-pull-applied-to-flybot</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/lasagna-pull-applied-to-flybot</guid><pubDate>Sat, 08 Apr 2023 08:16:25 +0000</pubDate><description>
How we leverage `lasagna-pull` in the flybot.sg Clojure web app to define a pure data API.
</description><content:encoded><![CDATA[<h2>Prerequisites</h2><p>If you are not familiar with <a href='https://github.com/flybot-sg/lasagna-pull'>lasagna-pull</a>, please refer to the doc <a href='https://www.loicblanchard.me/blog/lasagna-pull'>Lasagna Pull: Precisely select from deep nested data</a></p><h2>Goal</h2><p>In this document, I will show you how we leverage <code>lasagna-pull</code> in the <a href='https://github.com/skydread1/flybot.sg'>flybot app</a> to define a pure data API.</p><h2>Defines API as pure data</h2><p>A good use case of the pattern is as parameter in a post request.</p><p>In our backend, we have a structure representing all our endpoints:</p><pre><code class="clojure">;; BACKEND data structure
&#40;defn pullable-data
  &quot;Path to be pulled with the pull-pattern.
   The pull-pattern `:with` option will provide the params to execute the function
   before pulling it.&quot;
  &#91;db session&#93;
  {:posts {:all          &#40;fn &#91;&#93; &#40;get-all-posts db&#41;&#41;
           :post         &#40;fn &#91;post-id&#93; &#40;get-post db post-id&#41;&#41;
           :new-post     &#40;with-role session :editor
                           &#40;fn &#91;post&#93; &#40;add-post db post&#41;&#41;&#41;
           :removed-post &#40;with-role session :editor
                           &#40;fn &#91;post-id user-id&#93; &#40;delete-post db post-id user-id&#41;&#41;&#41;}
   :users {:all          &#40;with-role session :owner
                           &#40;fn &#91;&#93; &#40;get-all-users db&#41;&#41;&#41;
           :user         &#40;fn &#91;id&#93; &#40;get-user db id&#41;&#41;
           :removed-user &#40;with-role session :owner
                           &#40;fn &#91;id&#93; &#40;delete-user db id&#41;&#41;&#41;
           :auth         {:registered &#40;fn &#91;id email name picture&#93; &#40;register-user db id email name picture&#41;&#41;
                          :logged     &#40;fn &#91;&#93; &#40;login-user db &#40;:user-id session&#41;&#41;&#41;}
           :new-role     {:admin &#40;with-role session :owner
                                   &#40;fn &#91;email&#93; &#40;grant-admin-role db email&#41;&#41;&#41;
                          :owner &#40;with-role session :owner
                                   &#40;fn &#91;email&#93; &#40;grant-owner-role db email&#41;&#41;&#41;}
           :revoked-role {:admin &#40;with-role session :owner
                                   &#40;fn &#91;email&#93; &#40;revoke-admin-role db email&#41;&#41;&#41;}}}&#41;
</code></pre><p>This resembles a REST API structure.</p><p>Since the API "route" information is contained within the pattern keys themselves, all the http requests with a pattern as params can hit the same backend URI.</p><p>So we have a single route for all pattern http request:</p><pre><code class="clojure">&#40;into &#40;auth/auth-routes oauth2-config&#41;
      &#91;&#91;&quot;/pattern&quot; {:post ring-handler}&#93; ;; all requests with pull pattern go here
       &#91;&quot;/users/logout&quot; {:get &#40;auth/logout-handler client-root-path&#41;}&#93;
       &#91;&quot;/oauth/google/success&quot; {:get ring-handler :middleware &#91;&#91;auth/authentification-middleware client-root-path&#93;&#93;}&#93;
       &#91;&quot;/&#42;&quot; {:get {:handler index-handler}}&#93;&#93;&#41;
</code></pre><p>Therefore the pull pattern:</p><ul><li>Describes the API routes</li><li>Provides the data expected by the server in its <code>:with</code> option for the concerned endpoints</li><li>Describes what is asked by the client to only return relevant data</li><li>Can easily perform authorization</li></ul><h2>Example: pull a post</h2><p>For instance, getting a specific post, meaning with the "route": <code>:posts :post</code>, can be done this way:</p><pre><code class="clojure">&#40;&#40;pull/qfn
  {:posts
   {&#40;list :post :with &#91;s/post-1-id&#93;&#41; ;; provide required params to pullable-data :post function
    {:post/id '?
     :post/page '?
     :post/css-class '?
     :post/creation-date '?
     :post/last-edit-date '?
     :post/author {:user/id '?
                   :user/email '?
                   :user/name '?
                   :user/picture '?
                   :user/roles &#91;{:role/name '?
                                 :role/date-granted '?}&#93;}
     :post/last-editor {:user/id '?
                        :user/email '?
                        :user/name '?
                        :user/picture '?
                        :user/roles &#91;{:role/name '?
                                      :role/date-granted '?}&#93;}
     :post/md-content '?
     :post/image-beside {:image/src '?
                         :image/src-dark '?
                         :image/alt '?}
     :post/default-order '?}}}
  '&amp;? ;; bind the whole data
  &#41;&#41;
; =&gt; 
{:posts
 {:post
  #:post{:id #uuid &quot;64cda032-b4e4-431e-bd85-0dbe34a8feeb&quot; ;; s/post-1-id
         :page :home
         :css-class &quot;post-1&quot;
         :creation-date #inst &quot;2023-01-04T00:00:00.000-00:00&quot;
         :last-edit-date #inst &quot;2023-01-05T00:00:00.000-00:00&quot;
         :author #:user{:id &quot;alice-id&quot;
                        :email &quot;alice@basecity.com&quot;
                        :name &quot;Alice&quot;
                        :picture &quot;alice-pic&quot;
                        :roles &#91;#:role{:name :editor
                                       :date-granted
                                       #inst &quot;2023-01-02T00:00:00.000-00:00&quot;}&#93;}
         :last-editor #:user{:id &quot;bob-id&quot;
                             :email &quot;bob@basecity.com&quot;
                             :name &quot;Bob&quot;
                             :picture &quot;bob-pic&quot;
                             :roles &#91;#:role{:name :editor
                                            :date-granted
                                            #inst &quot;2023-01-01T00:00:00.000-00:00&quot;}
                                     #:role{:name :admin
                                            :date-granted
                                            #inst &quot;2023-01-01T00:00:00.000-00:00&quot;}&#93;}
         :md-content &quot;#Some content 1&quot;
         :image-beside #:image{:src &quot;https://some-image.svg&quot;
                               :src-dark &quot;https://some-image-dark-mode.svg&quot;
                               :alt &quot;something&quot;}
         :default-order 0}}}
</code></pre><p>It is important to understand that the param <code>s/post-1-id</code>  in <code>&#40;list :post :with &#91;#uuid s/post-1-id&#93;&#41;</code> was passed to <code>&#40;fn &#91;post-id&#93; &#40;get-post db post-id&#41;&#41;</code> in <code>pullable-data</code>. </p><p>The function returned the post fetched from the db.</p><p>We decided to fetch all the information of the post in our pattern but we could have just fetch some of the keys only:</p><pre><code class="clojure">&#40;&#40;pull/qfn
  {:posts
   {&#40;list :post :with &#91;s/post-1-id&#93;&#41; ;; only fetch id and page even though all the other keys have been returned here
    {:post/id '?
     :post/page '?}}}
  '&amp;?&#41;&#41;
;=&gt; {:posts
     {:post
      {:post/id #uuid &quot;64cda032-b4e4-431e-bd85-0dbe34a8feeb&quot;
       :post/page :home}}}
</code></pre><p>The function <code>&#40;fn &#91;post-id&#93; &#40;get-post db post-id&#41;&#41;</code> returned <strong>all</strong> the post keys but we only select the <code>post/id</code> and <code>post/page</code>.</p><p>So we provided the required param <code>s/post-1-id</code> to the endpoint <code>:post</code> and we also specified what information we want to pull: <code>:post/id</code> and <code>:post/page</code>.</p><p>You can start to see how convenient that is as a frontend request to the backend. our post request body can just be a <code>pull-pattern</code>! (more on this further down in the doc).</p><h2>Post data validation</h2><p>It is common to use <a href='https://github.com/metosin/malli'>malli</a> schema to validate data.</p><p>Here is the malli schema for the post data structure we used above:</p><pre><code class="clojure">&#40;def post-schema
  &#91;:map {:closed true}
   &#91;:post/id :uuid&#93;
   &#91;:post/page :keyword&#93;
   &#91;:post/css-class {:optional true} &#91;:string {:min 3}&#93;&#93;
   &#91;:post/creation-date inst?&#93;
   &#91;:post/last-edit-date {:optional true} inst?&#93;
   &#91;:post/author user-schema&#93;
   &#91;:post/last-editor {:optional true} user-schema&#93;
   &#91;:post/md-content &#91;:and
                      &#91;:string {:min 10}&#93;
                      &#91;:fn
                       {:error/message &quot;Level 1 Heading `#` missing in markdown.&quot;}
                       md/has-valid-h1-title?&#93;&#93;&#93;
   &#91;:post/image-beside
    {:optional true}
    &#91;:map
     &#91;:image/src &#91;:string {:min 10}&#93;&#93;
     &#91;:image/src-dark &#91;:string {:min 10}&#93;&#93;
     &#91;:image/alt &#91;:string {:min 5}&#93;&#93;&#93;&#93;
   &#91;:post/default-order {:optional true} nat-int?&#93;&#93;&#41;
</code></pre><h2>Pattern data validation</h2><p><code>lasagna-pull</code> also allows us to provide schema alongside the pattern to validate 2 things:</p><ul><li>the pattern format is correct</li><li>the pattern content respects a malli schema</li></ul><p>This is very good because we can have a malli schema for the entire <code>pullable-data</code> structure like so:</p><pre><code class="clojure">&#40;def api-schema
  &quot;All keys are optional because it is just a data query schema.
   maps with a property :preserve-required set to true have their keys remaining unchanged.&quot;
  &#40;all-keys-optional
   &#91;:map
    {:closed true}
    &#91;:posts
     &#91;:map
      &#91;:post &#91;:=&gt; &#91;:cat :uuid&#93; post-schema&#93;&#93; ;; route from our get post example 
      &#91;:all &#91;:=&gt; &#91;:cat&#93; &#91;:vector post-schema&#93;&#93;&#93;
      &#91;:new-post &#91;:=&gt; &#91;:cat post-schema-create&#93; post-schema&#93;&#93;
      &#91;:removed-post &#91;:=&gt; &#91;:cat :uuid :string&#93; post-schema&#93;&#93;&#93;&#93;
    &#91;:users
     &#91;:map
      &#91;:user &#91;:=&gt; &#91;:cat :string&#93; user-schema&#93;&#93;
      &#91;:all &#91;:=&gt; &#91;:cat&#93; &#91;:vector user-schema&#93;&#93;&#93;
      &#91;:removed-user &#91;:=&gt; &#91;:cat :string&#93; user-schema&#93;&#93;
      &#91;:auth &#91;:map
              &#91;:registered &#91;:=&gt; &#91;:cat :string user-email-schema :string :string&#93; user-schema&#93;&#93;
              &#91;:logged &#91;:=&gt; &#91;:cat&#93; user-schema&#93;&#93;&#93;&#93;
      &#91;:new-role &#91;:map
                  &#91;:admin &#91;:=&gt; &#91;:cat user-email-schema&#93; user-schema&#93;&#93;
                  &#91;:owner &#91;:=&gt; &#91;:cat user-email-schema&#93; user-schema&#93;&#93;&#93;&#93;
      &#91;:revoked-role &#91;:map
                      &#91;:admin &#91;:=&gt; &#91;:cat user-email-schema&#93; user-schema&#93;&#93;&#93;&#93;&#93;&#93;&#93;&#41;&#41;
</code></pre><p>If we go back to the scenario where we want to fetch a specific post from the DB, we can see that we are indeed having a function as params of the key <code>:post</code> that expects one param: a uuid:</p><pre><code class="clojure">&#91;:post &#91;:=&gt; &#91;:cat :uuid&#93; post-schema&#93;&#93; 
</code></pre><p>It corresponds to the pattern part:</p><pre><code class="clojure">&#40;list :post :with &#91;s/post-1-id&#93;&#41;
</code></pre><p>And <code>lasagna-pull</code> provides validation of the function's params which is very good to be sure the proper data is sent to the server!</p><p>Plus, in case the params given to one of the routes are not valid, the function won't even be executed.</p><p>So now we have a way to do post request to our backend providing a pull-pattern as the request body and our server can validate this pattern format and content as the data is being pulled.</p><h2>Pattern query context</h2><h3>How it works</h3><p>Earlier, I asked you to assume that the function from <code>pullable-data</code> was returning a post data structure.</p><p>In reality, it is a bit more complex than this because what is returned by the different functions (endpoints) in <code>pullable-data</code> is a map. For instance:</p><pre><code class="clojure">;; returned by get-post
{:response &#40;db/get-post db post-id&#41;} ;; note the response key here

;; returned by register-user
{:response user
 :effects  {:db {:payload &#91;user&#93;}} ;; the db transaction description to be made
 :session  {:user-id user-id} ;; the user info to be added to the session
}
</code></pre><p>This is actually a problem because our pattern for a post is:</p><pre><code class="clojure">{:posts
  {&#40;list :post :with &#91;s/post-1-id&#93;&#41;
    {:post/id '?}}}
</code></pre><p>and with what is returned by <code>&#40;fn &#91;post-id&#93; &#40;get-post db post-id&#41;&#41;</code>, we should have:</p><pre><code class="clojure">{:posts
  {&#40;list :post :with &#91;s/post-1-id&#93;&#41;
    {:response ;; note the response here
  	  {:post/id '?}}}}
</code></pre><p>Also, in case of a user registration for instance, you saw that we have other useful information such as</p><ul><li>effects: the db transaction to add the user to the db</li><li>session: some user info to add to the session.</li></ul><p>However we do not want to pull the <code>effects</code> and <code>session</code>. We just want a way to accumulate them somewhere.</p><p>We could perform the transaction directly and return the post, but we don't want that.</p><p>We prefer to accumulate side effects descriptions and execute them all at once in a dedicated <code>executor</code>.</p><p>The <code>response</code> needs to be added to the pulled data, but the <code>effects</code> and <code>session</code> need to be stored elsewhere and executed later on.</p><p>This is possible via a <code>modifier</code> and a <code>finalizer</code> context in the <code>pull/query</code> API.</p><p>In our case, we have a <code>mk-query</code> function that uses a <code>modifier</code> and <code>finalizer</code> to achieve what I described above:</p><pre><code class="clojure">&#40;defn mk-query
  &quot;Given the pattern, make an advance query using a context:
   modifier: gather all the effects description in a coll
   finalizer: assoc all effects descriptions in the second value of pattern.&quot;
  &#91;pattern&#93;
  &#40;let &#91;effects-acc &#40;transient &#91;&#93;&#41;
        session-map &#40;transient {}&#41;&#93;
    &#40;pull/query
     pattern
     &#40;pull/context-of
      &#40;fn &#91;&#95; &#91;k {:keys &#91;response effects session error&#93; :as v}&#93;&#93;
        &#40;when error
          &#40;throw &#40;ex-info &quot;executor-error&quot; error&#41;&#41;&#41;
        &#40;when session ;; assoc session to the map session
          &#40;reduce
           &#40;fn &#91;res &#91;k v&#93;&#93; &#40;assoc! res k v&#41;&#41;
           session-map
           session&#41;&#41;
        &#40;when effects ;; conj the db transaction description to effects vector
          &#40;conj! effects-acc effects&#41;&#41;
        &#40;if response
          &#91;k response&#93;
          &#91;k v&#93;&#41;&#41;
      #&#40;assoc % ;; returned the whole pulled data and assoc the effects and session to it
              :context/effects  &#40;persistent! effects-acc&#41;
              :context/sessions &#40;persistent! session-map&#41;&#41;&#41;&#41;&#41;&#41;
</code></pre><h3>Example of post creation</h3><p>Let's have a look at an example:</p><p>We want to add a new post. When we make a request for a new post, if everything works fine, the pullable-data function at the route <code>:new-post</code> returns a map such as:</p><pre><code class="clojure">{:response full-post ;; the pullable data to return to the client
 :effects  {:db {:payload posts}} ;; the new posts to be added to the db
}
</code></pre><p>The pull pattern for such request can be like this:</p><pre><code class="clojure">{:posts
 {&#40;list :new-post :with &#91;post-in&#93;&#41; ;; post-in is a full post to be added with all required keys
  {:post/id '?
   :post/page '?
   :post/default-order '?}}}
</code></pre><p>The <code>post-in</code> is provided to the pullable-data function of the key <code>:new-post</code>.</p><p>The function of <code>add-post</code> actually determine all the new <code>:post/default-order</code> of the posts given the new post. That is why we see in the side effects that several <code>posts</code> are returned because we need to have their order updated in db.</p><p>Running this pattern with the pattern <strong>context</strong> above returns:</p><pre><code class="clojure">{&amp;?               {:posts {:new-post {:post/id #uuid &quot;64cda032-3dae-4845-b7b2-e4a6f9009cbd&quot;
                                      :post/page :home
                                      :post/creation-date #inst &quot;2023-01-07T00:00:00.000-00:00&quot;
                                      :post/default-order 2}}}
 :context/effects &#91;{:db {:payload &#91;{:post/id #uuid &quot;64cda032-3dae-4845-b7b2-e4a6f9009cbd&quot;
                                    :post/page :home
                                    :post/md-content &quot;#Some content 3&quot;
                                    :post/creation-date #inst &quot;2023-01-07T00:00:00.000-00:00&quot;
                                    :post/author {:user/id &quot;bob-id&quot;}
                                    :post/default-order 2}&#93;}}&#93;
 :context/sessions {}}
</code></pre><ul><li>the response has been returned from the :with function to the pattern in the <code>'&amp;?</code> key</li><li>the effects have been accumulated and assoc in <code>:context/effects</code></li><li>there was no data to be added to the session</li></ul><p>Then, in the ring response, we can just return the value of <code>&amp;?</code></p><p>Also, the effects can be executed in a dedicated executor functions all at once.</p><p>This allows us to deal with pure data until the very last moment when we run all the side effects (db transaction and session) in one place only we call <code>executor</code>.</p><h2>Saturn handler</h2><p>In our system, we have a component called the <code>saturn-handler</code>. The component <code>ring-handler</code> depends on it.</p><p>In order to isolate the side effects as much as we can, our endpoints from our <code>pullable-data</code>, highlighted previously, do not perform side effects but return <strong>descriptions</strong> in pure data of the side effects to be done. These side effects are the ones we gather in <code>:context/effects</code> and <code>:context/sessions</code> using the pull-pattern's query context.</p><p>The saturn-handler returns a map with the <code>response</code> (data pulled and requested in the client pattern) to be sent to the client, the <code>effect-desc</code> to be perform (in our case, just db transactions) and the <code>session</code> update to be done:</p><pre><code class="clojure">&#40;defn saturn-handler
  &quot;A saturn handler takes a ring request enhanced with additional keys form the injectors.
   The saturn handler is purely functional.
   The description of the side effects to be performed are returned and they will be executed later on in the executors.&quot;
  &#91;{:keys &#91;params body-params session db&#93;}&#93;
  &#40;let &#91;pattern &#40;if &#40;seq params&#41; params body-params&#41;
        data    &#40;op/pullable-data db session&#41;
        {:context/keys &#91;effects sessions&#93; :as resp}
        &#40;pull/with-data-schema v/api-schema &#40;&#40;mk-query pattern&#41; data&#41;&#41;&#93;
    {:response     &#40;'&amp;? resp&#41;
     :effects-desc effects
     :session      &#40;merge session sessions&#41;}&#41;&#41;
</code></pre><p>You can also notice that the data is being validated via <code>pull/with-data-schema</code>. In case of validation error, since we do not have any side effects done during the pulling, an error will be thrown and no mutations will be done.</p><p>Having no side-effects at all makes it way easier to tests and debug and it is more predictable.</p><p>Finally, the <code>ring-handler</code> will be the component responsible to <strong>execute</strong> all the side effects at once. </p><p>So the <code>saturn-handler</code> purpose was to be sure the data is being pulled properly, validated using malli, and that the side effects descriptions are gathered in one place to be executed later on.</p>]]></content:encoded></item><item><title>Clojure Mono Repo example : server + 2 clients</title><link>https://www.loicblanchard.me/blog/clojure-mono-repo</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/clojure-mono-repo</guid><pubDate>Thu, 16 Feb 2023 08:16:25 +0000</pubDate><description>
Example of a Clojure mono-repo structure for a web server and 2 clients (web and mobile).
</description><content:encoded><![CDATA[<h2>Context</h2><p>Our app <a href='https://github.com/skydread1/flybot.sg'>skydread1/flybot.sg</a> is a full-stack Clojure <strong>web</strong> and <strong>mobile</strong> app.</p><p>We opted for a mono-repo to host:</p><ul><li>the <code>server</code>: Clojure app</li><li>the <code>web</code> client: Reagent (React) app using Re-Frame</li><li>the <code>mobile</code> client: Reagent Native (React Native) app using Re-Frame</li></ul><p>Note that the web app does not use NPM at all. However, the React Native mobile app does use NPM and the <code>node&#95;modules</code> need to be generated.</p><p>By using only one <code>deps.edn</code>, we can easily starts the different parts of the app.</p><h2>Goal</h2><p>The goal of this document is to highlight the mono-repo structure and how to run the different parts (dev, test, build etc).</p><h2>Repo structure</h2><pre><code>‚îú‚îÄ‚îÄ client
‚îÇ   ‚îú‚îÄ‚îÄ common
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ flybot.client.common
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ flybot.client.common
‚îÇ   ‚îú‚îÄ‚îÄ mobile
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ flybot.client.mobile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ flybot.client.mobile
‚îÇ   ‚îî‚îÄ‚îÄ web
‚îÇ       ‚îú‚îÄ‚îÄ src
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ flybot.client.web
‚îÇ       ‚îî‚îÄ‚îÄ test
‚îÇ           ‚îî‚îÄ‚îÄ flybot.client.web
‚îú‚îÄ‚îÄ common
‚îÇ   ‚îú‚îÄ‚îÄ src
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ flybot.common
‚îÇ   ‚îî‚îÄ‚îÄ test
‚îÇ       ‚îî‚îÄ‚îÄ flybot.common
‚îú‚îÄ‚îÄ server
‚îÇ   ‚îú‚îÄ‚îÄ src
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ flybot.server
‚îÇ   ‚îî‚îÄ‚îÄ test
‚îÇ       ‚îî‚îÄ‚îÄ flybot.server
</code></pre><ul><li><code>server</code> dir contains then <code>.clj</code> files</li><li><code>common</code> dir the <code>.cljc</code> files</li><li><code>clients</code> dir the <code>.cljs</code> files.</li></ul><h2>Deps Management</h2><p>You can have a look at the <a href='https://github.com/skydread1/flybot.sg/blob/master/deps.edn'>deps.edn</a>.</p><p>We can use namespaced aliases in <code>deps.edn</code> to make the process clearer.</p><p>I will go through the different aliases and explain their purposes and how to I used them to develop the app.</p><h2>Common libraries</h2><h3>clj and cljc deps</h3><p>First, the root deps of the deps.edn, inherited by all aliases:</p><h4>Both frontend and backend</h4><ul><li>org.clojure/clojure</li><li>metosin/malli</li><li>metosin/reitit</li><li>metosin/muuntaja</li><li>sg.flybot/lasagna-pull</li></ul><h4>Backend</h4><ul><li>ring/ring-defaults</li><li>aleph/aleph</li><li>robertluo/fun-map</li><li>datalevin/datalevin</li><li>skydread1/reitit-oauth2 </li></ul><p>The deps above are used in both <code>server/src</code> and <code>common/src</code> (clj and cljc files).</p><p>So every time you start a <code>deps</code> REPL or a <code>deps+figwheel</code> REPL, these deps will be loaded.</p><h3>Sample data</h3><p>In the <a href='https://github.com/skydread1/flybot.sg/blob/master/common/test/flybot/common/test_sample_data.cljc'>common/test/flybot/common/test<i>sample</i>data.cljc</a> namespace, we have sample data that can be loaded in both backend dev system of frontend dev systems.</p><p>This is made possible by reader conditionals clj/cljs.</p><h3>IDE integration</h3><p>I use the <code>calva</code> extension in VSCode to jack-in deps and figwheel REPLs but you can use Emacs if you prefer for instance.</p><p>What is important to remember is that, when you work on the backend only, you just need a <code>deps</code> REPL. There is no need for figwheel since we do not modify the cljs content. So in this scenario, the frontend is fixed (the main.js is generated and not being reloaded) but the backend changes (the <code>clj</code> files and <code>cljc</code> files).</p><p>However, when you work on the frontend, you need to load the backend deps to have your server running but you also need to recompile the js when a cljs file is saved. Therefore your need both <code>deps+figwheel</code> REPL. So in this scenario, the backend is fixed and running but the frontend changes (the <code>cljs</code> files and <code>cljc</code> files)</p><p>You can see that the <strong>common</strong> <code>cljc</code> files are being watched in both scenarios which makes sense since they "become" clj or cljs code depending on what REPL type you are currently working in.</p><h2>Server aliases</h2><p>Following are the aliases used for the server:</p><ul><li><code>:jvm-base</code>: JVM options to make datalevin work with java version > java8</li><li><code>:server/dev</code>: clj paths for the backend systems and tests</li><li><code>:server/test</code>: Run clj tests</li></ul><h2>Client common aliases</h2><p>Following is the alias used for both web and mobile clients:</p><ul><li><code>:client</code>: deps for frontend libraries common to web and react native.</li></ul><p>The extra-paths contains the <code>cljs</code> files.</p><p>We can note the <code>client/common/src</code> path that contains most of the <code>re-frame</code> logic because most subscriptions and events work on both web and react native right away!</p><p>The main differences between the re-frame logic for Reagent and Reagent Native have to do with how to deal with Navigation and oauth2 redirection. That is the reason we have most of the logic in a <strong>common</strong> dir in <code>client</code>.</p><h2>Mobile Client</h2><p>Following are the aliases used for the <strong>mobile</strong> client:</p><ul><li><code>:mobile/rn</code>: contains the cljs deps only used for react native. They are added on top of the client deps.</li><li><code>:mobile/ios</code>: starts the figwheel REPL to work on iOS.</li></ul><h2>Web Client</h2><p>Following are the aliases used for the <strong>web</strong> client:</p><ul><li><code>:web/dev</code>: starts the dev REPL</li><li><code>:web/prod</code>: generates the optimized js bundle main.js</li><li><code>:web/test</code>: runs the cljs tests</li><li><code>:web/test-headless</code>: runs the headless cljs tests (fot GitHub CI)</li></ul><h2>CI/CD aliases</h2><h3>build.clj</h3><p>Following is the alias used to build the js bundle or a uberjar:</p><ul><li><code>:build</code>: <a href='https://github.com/clojure/tools.build'>clojure/tools.build</a> is used to build the main.js and also an uber jar for local testing, we use .</li></ul><p>The build.clj contains the different build functions:</p><ul><li>Build frontend js bundle: <code>clj -T:build js-bundle</code></li><li>Build backend uberjar: <code>clj -T:build uber</code></li><li>Build both js and jar: <code>clj -T:build uber+js</code></li></ul><h3>Jibbit</h3><p>Following is the alias used to build an image and push it to local docker or AWS ECR:</p><ul><li><code>:jib</code>: build image and push to image repo</li></ul><h2>Antq</h2><p>Following is the alias used to points out outdated dependencies</p><ul><li><code>:outdated</code>: prints the outdated deps and their last available version</li></ul><h2>Notes on Mobile CD</h2><p>We have not released the mobile app yet, that is why there is no aliases related to CD for react native yet.</p><h2>Conclusion</h2><p>This is one solution to handle server and clients in the same repo.</p><p>Feel free to consult the complete <a href='https://github.com/skydread1/flybot.sg/blob/master/deps.edn'>deps.edn</a> content.</p><p>It is important to have a clear directory structure to only load required namespaces and avoid errors.</p><p>Using <code>:extra-paths</code> and <code>:extra-deps</code> in deps.edn is important because it prevent deploying unnecessary namespaces and libraries on the server and client.</p><p>Adding namespace to the aliases make the distinction between backend, common and client (web and mobile) clearer.</p><p>Using <code>deps</code> jack-in for server only work and <code>deps+figwheel</code> for frontend work is made easy using <code>calva</code> in VSCode (work in other editors as well).</p>]]></content:encoded></item><item><title>Reagent React Native Mobile App</title><link>https://www.loicblanchard.me/blog/reagent-native-app</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/reagent-native-app</guid><pubDate>Fri, 03 Feb 2023 08:16:25 +0000</pubDate><description>
Reagent React Native mobile app reusing re-frame logic from exiting web client.
</description><content:encoded><![CDATA[<h2>Prerequisites</h2><p>This project is stored alongside the backend and the web frontend in the mono-repo: <a href='https://github.com/skydread1/flybot.sg'>skydread1/flybot.sg</a></p><p>The codebase is a full-stack <strong>Clojure(Script)</strong> app. The backend is written in <strong>Clojure</strong> and the web and mobile clients are written in <strong>ClojureScript</strong>.</p><p>For the web app, we use <a href='https://github.com/reagent-project/reagent'>reagent</a>, a ClojureScript interface for <code>React</code>.</p><p>For the mobile app, we use <a href='https://github.com/vouch-opensource/reagent-react-native'>reagent-react-native</a>, a ClojureScript interface for <code>React Native</code>.</p><p>The mono-repo structure is as followed:</p><pre><code>‚îú‚îÄ‚îÄ client
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ common
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ src
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ flybot.client.common
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ test
‚îÇ¬†¬† ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ flybot.client.common
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ mobile
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ src
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ flybot.client.mobile
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ test
‚îÇ¬†¬† ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ flybot.client.mobile
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ web
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ src
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ flybot.client.web
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ test
‚îÇ¬†¬†         ‚îî‚îÄ‚îÄ flybot.client.web
‚îú‚îÄ‚îÄ common
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ src
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ flybot.common
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ test
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ flybot.common
‚îú‚îÄ‚îÄ server
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ src
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ flybot.server
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ test
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ flybot.server
</code></pre><p>So far, the RN app has only been tested on iOS locally.</p><h2>Rational</h2><p>The goal was to have a mobile app targeting both iOS and Android, written in <code>ClojureScript</code>, which can reuse most of our web frontend logic.</p><p>To do so, I used <code>React Native</code> for the following reasons:</p><ul><li>Integrate very well with <a href='https://github.com/bhauman/figwheel-main'>figwheel-main</a> and <a href='https://github.com/day8/re-frame'>re-frame</a></li><li>Target both iOS and Android</li><li>Does not necessitate too much configuration to get it running</li><li>React Native has an overall good documentation</li></ul><h2>Setup</h2><p>To get React Native working, you need to follow a few steps.</p><p>The setup steps are well described in the <a href='https://figwheel.org/docs/react-native.html'>Figwheel doc</a>.</p><h3>npm</h3><p>The Figwheel doc has a <a href='https://figwheel.org/docs/npm.html'>dedicated section</a> to install and setup NPM in a project. The best way to install npm is to use <a href='https://github.com/nvm-sh/nvm'>nvm</a>.</p><h3>React Native</h3><p>To do mobile dev, some tools need to be installed and the react native <a href='https://reactnative.dev/docs/next/environment-setup'>doc</a> has the instructions on how to prepare the environment.</p><h3>Ruby</h3><p>The default Ruby version installed on MacOS is not enough to work with React Native. Actually, React Native needs a specific version of Ruby hence the use of a ruby version manager. I used <a href='https://github.com/rbenv/rbenv'>rbenv</a>.</p><pre><code class="bash">&#126;:brew install rbenv ruby-build

&#126;:rbenv -v
rbenv 1.2.0
</code></pre><p>React Native uses <a href='https://github.com/facebook/react-native/blob/main/template/_ruby-version'>this version</a> of ruby so we need to download it.</p><pre><code class="bash"># install proper ruby version
&#126;:rbenv install 2.7.6

# set ruby version as default
&#126;:rbenv global 2.7.6
</code></pre><p>We also need to add these 2 lines to the .zshrc</p><pre><code class="bash">export PATH=&quot;$HOME/.rbenv/bin:$PATH&quot;
eval &quot;$&#40;rbenv init -&#41;&quot;
</code></pre><p>Finally we make sure we have the correct version:</p><pre><code class="bash">&#126;:ruby -v
ruby 2.7.6p219 &#40;2022-04-12 revision c9c2245c0a&#41; &#91;arm64-darwin22&#93;
</code></pre><h3>Ruby's Bundler</h3><p>From the doc:</p><p>Ruby's¬†<a href='https://bundler.io/'>Bundler</a> is a Ruby gem that helps managing the Ruby dependencies of your project. We need Ruby to install Cocoapods and using Bundler will make sure that all the dependencies are aligned and that the project works properly.</p><pre><code class="bash"># install the bundler
&#126;:gem install bundler
Fetching bundler-2.4.5.gem
Successfully installed bundler-2.4.5
...

# Check the location where gems are being installed
&#126;:gem env home
/Users/loicblanchard/.rbenv/versions/2.7.6/lib/ruby/gems/2.7.0
</code></pre><h3>Xcode</h3><p>From the doc:</p><blockquote><p> The easiest way to install <code>Xcode</code> is via the¬†<a href='https://itunes.apple.com/us/app/xcode/id497799835?mt=12'>Mac App Store</a> . Installing Xcode will also install the iOS Simulator and all the necessary tools to build your iOS app. </p></blockquote><p>I downloaded it from the apple store.</p><p><code>Xcode command line</code> tools also needs to be installed. It can be chosen in <code>Xcode‚ÜíSettings‚ÜíLocations</code></p><pre><code class="bash">&#126;:xcode-select -p
/Library/Developer/CommandLineTools
</code></pre><h3>Installing an iOS Simulator in Xcode</h3><p>It should be already installed.</p><h3>React Native Command Line Interface</h3><p>We can use <code>npx</code> directly because it was shipped with <code>npm</code>.</p><h3>CocoaPods</h3><p><a href='https://github.com/CocoaPods/CocoaPods'>CocoaPods</a> is required to use the Ruby‚Äôs Bundler and we can install it using <a href='https://github.com/rubygems/rubygems'>rubygems</a>:</p><pre><code class="bash">sudo gem install cocoapods

# check version
&#126;:gem which cocoapods
/Users/loicblanchard/.rbenv/versions/2.7.6/lib/ruby/gems/2.7.0/gems/cocoapods-1.11.3/lib/cocoapods.rb
</code></pre><h3>Troubleshooting</h3><p>In case of the error <a href='https://github.com/CocoaPods/CocoaPods/issues/11641'>Multiple Profiles</a>, we need to switch to the Xcode cli manually like so:</p><pre><code class="bash">sudo xcode-select --switch /Applications/Xcode.app
</code></pre><h2>Create Project</h2><p>We now should have all the tools installed to start a React Native project on Mac targeting iOS.</p><pre><code class="bash"># setup project
npx react-native init MyAwesomeProject
</code></pre><h3>Running the project</h3><pre><code class="bash">npx react-native run-ios
</code></pre><p>This should open a simulator with the welcome React Native display.</p><h2>Integrate RN with Clojure and Figwheel</h2><p>Add an alias to the deps.edn:</p><pre><code class="clojure">:cljs/ios {:main-opts &#91;&quot;--main&quot;  &quot;figwheel.main&quot;
                       &quot;--build&quot; &quot;ios&quot;
                       &quot;--repl&quot;&#93;}
</code></pre><p>Note: We need to use cljs version <code>1.10.773</code> because the latest version causes this <a href='https://github.com/log4js-node/log4js-node/issues/1171'>error</a> which is hard to debug.</p><p>Also, we need to add the figwheel config for <code>ios</code> in <code>ios.cljs.edn</code> :</p><pre><code class="clojure">&#94;{:react-native :cli
  :watch-dirs &#91;&quot;client/mobile/src&quot; &quot;client/common/src&quot;&#93;}
{:main flybot.client.mobile.core
 :closure-defines {flybot.client.common.db.event/BASE-URI &quot;http://localhost:9500&quot;}}
</code></pre><p>And then we add the source files in the src folder like explained in the <a href='https://figwheel.org/docs/react-native.html'>figwheel doc</a>.</p><p>To run the project, we start a REPLs (clj and cljs) with the proper aliases and in another terminal, we can run <code>run npm ios</code> to start the Xcode simulator.</p><p>For more details regarding the aliases: have a look at the <a href='https://github.com/skydread1/flybot.sg'>README</a></p><h2>Deps management</h2><p>If we want to add a npm package, we need 2 steps:</p><pre><code class="bash">npm i my-npm-package
cd ios
pod install
cd ..
</code></pre><h2>Troubleshooting</h2><p>In case of the error <a href='https://stackoverflow.com/questions/73268848/i-am-trying-to-work-with-react-navigation-library-but-this-issue-keeps-coming'>RNSScreenStackHeaderConfig</a>, we need to:</p><pre><code class="bash">npm i react-native-gesture-handler
cd ios
pod install
cd ..

# We restart the similutor and the error should be gone
</code></pre><h2>APP architecture and features</h2><h3>HTTP</h3><p>Regarding the http request made by the re-frame fx <code>http-xhrio</code>, it should work right away, same as for the web, but we just need to manually pass the cookie to the header as RN do not manage cookie for us like the web does.</p><p>Passing the cookie in the request was quite straight forward, I just added¬†<code>:headers {:cookie my-cookie}</code> to the¬†<code>:http-xhrio</code> fx for all the requests that require a session for the mobile app.</p><h3>Markdown to Native components</h3><p>I use <a href='https://github.com/andangrd/react-native-markdown-package'>react-native-markdown-package</a></p><pre><code class="bash">npm i react-native-markdown-package --save
</code></pre><h3>Font</h3><p>On iOS, I had to add the fonts in the <code>info.plist</code> like so:</p><pre><code class="xml">&lt;key&gt;UIAppFonts&lt;/key&gt;
	&lt;array&gt;
	  &lt;string&gt;AntDesign.ttf&lt;/string&gt;
	  &lt;string&gt;Entypo.ttf&lt;/string&gt;
	  &lt;string&gt;EvilIcons.ttf&lt;/string&gt;
	  &lt;string&gt;Feather.ttf&lt;/string&gt;
	  &lt;string&gt;FontAwesome.ttf&lt;/string&gt;
	  &lt;string&gt;FontAwesome5&#95;Brands.ttf&lt;/string&gt;
	  &lt;string&gt;FontAwesome5&#95;Regular.ttf&lt;/string&gt;
	  &lt;string&gt;FontAwesome5&#95;Solid.ttf&lt;/string&gt;
	  &lt;string&gt;Foundation.ttf&lt;/string&gt;
	  &lt;string&gt;Ionicons.ttf&lt;/string&gt;
	  &lt;string&gt;MaterialIcons.ttf&lt;/string&gt;
	  &lt;string&gt;MaterialCommunityIcons.ttf&lt;/string&gt;
	  &lt;string&gt;SimpleLineIcons.ttf&lt;/string&gt;
	  &lt;string&gt;Octicons.ttf&lt;/string&gt;
	  &lt;string&gt;Zocial.ttf&lt;/string&gt;
	&lt;/array&gt;
</code></pre><h2>Navigation</h2><h3>Navigators</h3><p>As for now we have 2 Navigators:</p><p><a href='https://reactnavigation.org/docs/tab-based-navigation/'>Tab Navigator</a></p><ul><li><code>login</code> screen</li><li><code>blog</code> screen: <a href='https://reactnavigation.org/docs/stack-navigator/'>Stack Navigator</a></li></ul><p><a href='https://reactnavigation.org/docs/stack-navigator/'>Stack Navigator</a></p><ul><li><code>post-lists</code> screen</li><li><code>post-read</code> screen</li><li><code>post-edit</code> screen</li><li><code>preview</code> screen</li></ul><p>So the Stack Navigator is inside the Tab Navigator blog screen.</p><h4>How to navigate</h4><p>For the navigation, we can use <code>re-frame</code> dispatch to change the navigation object ref to the new route.</p><p>Since we are using re-frame, we might not be able to access <code>props.navigation.navigate</code>.</p><p>However, we could store a reference to the navigation object in our re-frame DB so we can <a href='https://reactnavigation.org/docs/navigating-without-navigation-prop/'>Navigate without the navigation prop</a>.</p><p>Therefore, just using <code>re-frame/dispatch</code> to store the navigation ref to the <code>re-frame/db</code> and use <code>re-frame/subscribe</code> to get the ref (and so the nav params) is enough to handle navigation in our case. Thus, we do not use the props at all.</p><p>Regarding the hot reloading, the only way I found is to store the js state and navigation objects in atoms via <code>defonce</code> so we can remain on the same screen with same params as before the reload.</p><p>Note: Maybe I could use the AsyncStorage instead of the atoms even though it is only for dev purposes.</p><h2>Env variables</h2><p>One of the env variables we need to define is for the <code>uri</code>. For the web app, we can use relative path such as <code>/posts/all</code> but on mobile, there is no such thing as path and we would need to pass an absolute path such as <code>http://localhost:9500/posts/all</code> for instance in our case.</p><p>Therefore, we need to have some config to pass to the cljs build. It is possible to do so via the compiler option <a href='https://clojurescript.org/reference/compiler-options#closure-defines'>:closure-defines</a>.</p><p><code>:closure-defines</code> is a ClojureScript compiler option that allows you to specify a list of key-value pairs to be passed as JavaScript defines to the Google Closure Compiler. These defines can be used to conditionally compile code based on the value of the defined key. For example, you can define <code>:foo true</code> as a closure define and then use <code>#?&#40;:foo some-code&#41;</code> in your ClojureScript code to include <code>some-code</code> only when <code>:foo</code> is true.</p><p>Luckily, figwheel allows us to <a href='https://figwheel.org/docs/compile_config.html'>setup the closures-define in the config files</a>.</p><h2>OAuth2.0</h2><p>I redirect the request back to an intermediate end point that will directly fetch the user info and create a ring-session that contains the google tokens, the user-name and user-permissions. Then ring encrypts that for us and put that <code>ring-session</code> in a cookie that is sent to the client.</p><p>Thus, my clients only receive this ring-session id that will be passed to every request made (automatic for browser, manually added to request for mobile).</p><p>When the user logout, ring still passes a <code>ring-session</code> but it will be nil once decrypted by the server.</p><h3>How to redirect back to the mobile app</h3><p>To go back to the app after OAuth2.0 success, I had to add the scheme following to the <code>info.plist</code> for iOS:</p><pre><code class="xml">&lt;key&gt;CFBundleURLTypes&lt;/key&gt;
	&lt;array&gt;
	&lt;dict&gt;
		&lt;key&gt;CFBundleURLSchemes&lt;/key&gt;
		&lt;array&gt;
		&lt;string&gt;flybot-app&lt;/string&gt;
		&lt;/array&gt;
	&lt;/dict&gt;
</code></pre><p>Also, in <code>ios/AppDelegate.mm</code>, I added:</p><pre><code class="jsx">#import &lt;React/RCTLinkingManager.h&gt;

/// listen to incoming app links during your app's execution
- &#40;BOOL&#41;application:&#40;UIApplication &#42;&#41;application
   openURL:&#40;NSURL &#42;&#41;url
   options:&#40;NSDictionary&lt;UIApplicationOpenURLOptionsKey,id&gt; &#42;&#41;options
{
  return &#91;RCTLinkingManager application:application openURL:url options:options&#93;;
}
</code></pre><h2>Cookie management</h2><p>I store the cookie in async-storage for this because it is enough for our simple use case.</p><pre><code class="jsx">npm install @react-native-async-storage/async-storage
</code></pre><h3>AsyncStorage with re-frame</h3><p>Once the <code>ring-session</code> cookie is received from the server, a re-frame dispatch is triggered to set a cookie name <code>ring-session</code> in the device AsyncStorage. This event also updates the re-frame db value of <code>:user/cookie</code>.</p><p>One of the issues with AsyncStorage is that it returns a <code>Promise</code>. Therefore, we cannot access the value directly but only do something in the <code>.then</code> method. So, once the Promise is resolved, in the .then, we <code>re-frame/dispatch</code> an event that will update the re-frame/db.</p><p>The Promises to get or set a cookie from storage, being side effects, are done in a re-frame <code>reg-fx</code>. These <code>reg-fx</code> will be done inside <code>reg-event-fx</code> event. We want to respect the principle: <code>reg-fx</code> for pulling with side effect and <code>reg-event-fx</code> for pushing pure event.</p><h3>Ensure order of events</h3><p>We want to be sure the cookie is pulled from AsyncStorage before the db is initialised and all the posts and the user pulled. However, we cannot just dispatch the event to pull the cookie from AsyncStorage (returns a Promise that will then dispatch another event to update re-frame/db), and then dispatch the event to get all the posts from the server because there is no guarantee the cookie will be set before the request is made.</p><p>The solution is to dispatch the initialisation event inside the event from the Promise like so:</p><pre><code class="clojure">;; setup all db param and do get request to get posts, pages and user using cookie
&#40;rf/reg-event-fx
 :evt.app/initialize
 &#40;fn &#91;{:keys &#91;db&#93;} &#95;&#93; 
   {:db         &#40;assoc db ...&#41;
    :http-xhrio {:method          :post
                 :uri             &#40;base-uri &quot;/pages/all&quot;&#41;
                 :headers         {:cookie &#40;:user/cookie db&#41;}
                 :params          ...
                 :format          &#40;edn-request-format {:keywords? true}&#41;
                 :response-format &#40;edn-response-format {:keywords? true}&#41;
                 :on-success      &#91;:fx.http/all-success&#93;
                 :on-failure      &#91;:fx.http/failure&#93;}}&#41;&#41;

;; Impure fx to fet cookie from storage and dispatch new event to update db
&#40;rf/reg-fx ;; 2&#41;
 :fx.app/get-cookie-async-store
 &#40;fn &#91;k&#93;
   &#40;-&gt; &#40;async-storage/get-item k&#41; ;; Promise
       &#40;.then #&#40;rf/dispatch &#91;:evt.cookie/get %&#93;&#41;&#41;&#41;&#41;&#41;

;; Pure event triggered at the start of the app
&#40;rf/reg-event-fx ;; 1&#41;
 :evt.app/initialize-with-cookie
 &#40;fn &#91;&#95; &#91;&#95; cookie-name&#93;&#93;
   {:fx &#91;&#91;:fx.app/get-cookie-async-store cookie-name&#93;&#93;}&#41;&#41;

;; Pure event triggered by :fx.app/get-cookie-async-store
&#40;rf/reg-event-fx ;; 3&#41;
 :evt.cookie/get
 &#40;fn &#91;{:keys &#91;db&#93;} &#91;&#95; cookie-value&#93;&#93;
   {:db &#40;assoc db :user/cookie cookie-value&#41;
    :fx &#91;&#91;:dispatch &#91;:evt.app/initialize&#93;&#93;&#93;}&#41;&#41;
</code></pre><h2>Styling</h2><p>As for now, the styling is directly done in the <code>:style</code> keys of the RN component‚Äôs hiccups. Some more complex components have some styling that takes functions and or not in the <code>:style</code> keyword.</p><h2>Conclusion</h2><p>I hope that this unusual mobile app stack made you want to consider <code>ClojureScript</code> as a good alternative to build mobile apps.</p><p>It is important to note that the state management logic (re-frame) is the same at 90% for both the web app and the mobile app which is very convenient.</p><p>Finally, the web app is deployed but not the mobile app. All the codebase is open-source so feel free to take inspiration.</p>]]></content:encoded></item><item><title>Deploy full stack Clojure website to AWS</title><link>https://www.loicblanchard.me/blog/deploy-clj-app-to-aws</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/deploy-clj-app-to-aws</guid><pubDate>Fri, 20 Jan 2023 08:16:25 +0000</pubDate><description>
Example of how to deploy a containerized full-stack Clojure app in AWS EC2.
</description><content:encoded><![CDATA[<p>This is an example of how to deploy a containerized full-stack Clojure app in AWS EC2.</p><p>I will use the <a href='https://github.com/skydread1/flybot.sg'>flybot.sg website</a> as example of app to deploy.</p><h2>Prerequisites</h2><ul><li>Use an external DNS manager such as goDaddy for instance</li><li>The app does not handle SSL and domain/protocols redirect</li><li>The app used <code>datalevin</code> as embedded database which resides alongside the Clojure code inside a container</li><li>The app is an open-source mono-repo and hosted on my GitHub</li><li>We use ALB for redirects and certificates validations and ELB for static IP entry point.</li></ul><h2>Use Jibbit to push to ECR</h2><p>Instead of using datomic pro and having the burden to have a separate containers for the app and transactor, we decided to use <a href='https://github.com/juji-io/datalevin'>juji-io/datalevin</a> and its embedded storage on disk. Thus, we only need to deploy one container with the app.</p><p>To do so, we can use the library <a href='https://github.com/atomisthq/jibbit'>atomisthq/jibbit</a> baed on <a href='https://github.com/GoogleContainerTools/jib'>GoogleContainerTools/jib</a> (Build container images for Java applications).</p><p>It does not use docker to generate the image, so there is no need to have docker installed to generate images.</p><p><a href='https://github.com/atomisthq/jibbit'>jibbit</a> can be added as <code>alias</code> in deps.edn:</p><pre><code class="clojure">:jib
  {:deps {io.github.atomisthq/jibbit {:git/tag &quot;v0.1.14&quot; :git/sha &quot;ca4f7d3&quot;}}
   :ns-default jibbit.core
   :ns-aliases {jib jibbit.core}}
</code></pre><p>The <code>jib.edn</code> can be added in the project root with the configs to generate and push the image.</p><h3>Testing the app image locally</h3><p>Example of jibbit config to just create a local docker image:</p><pre><code class="clojure">;; example to create an docker image to be run with docker locally
{:main         clj.flybot.core
 :aliases      &#91;:jvm-base&#93;
 :user          &quot;root&quot;
 :group         &quot;root&quot;
 :base-image   {:image-name &quot;openjdk:11-slim-buster&quot;
                :type       :registry}
 :target-image {:image-name &quot;flybot/image:test&quot;
                :type       :docker}}
</code></pre><p>Then we can run the container:</p><pre><code>docker run \
--rm \
-it \
-p 8123:8123 \
-v db-v2:/datalevin/dev/flybotdb \
-e OAUTH2=&quot;secret&quot; \
-e ADMIN&#95;USER=&quot;secret&quot; \
-e SYSTEM=&quot;{:http-port 8123, :db-uri \&quot;datalevin/dev/flybotdb\&quot;, :oauth2-callback \&quot;http://localhost:8123/oauth/google/callback\&quot;}&quot; \
flybot/image:test
</code></pre><h3>AWS profile for CI</h3><p><a href='https://github.com/atomisthq/jibbit'>jibbit</a> can also read your local AWS credentials to directly push the generated image to your ECR (Elastic Container Registry).</p><p>You need to have aws cli installed (v2 or v1) and you need an env variable <code>$ECR&#95;REPO</code> setup with the ECR repo string.</p><p>You have several <a href='https://github.com/atomisthq/jibbit/blob/main/src/jibbit/aws_ecr.clj'>possibilities</a> to provide credentials to login to your AWS ECR.</p><p>Here is the <code>jib.edn</code> for the CI:</p><pre><code class="clojure">{:main           clj.flybot.core
 :target-image {:image-name &quot;$ECR&#95;REPO&quot;
                :type       :registry
                :authorizer {:fn   jibbit.aws-ecr/ecr-auth
                             :args {:type         :profile
                                    :profile-name &quot;flybot&quot;
                                    :region       &quot;region&quot;}}}}
</code></pre><h3>ENV variables</h3><p>I used <a href='https://docs.github.com/en/actions/security-guides/encrypted-secrets'>repository secrets</a> to handle AWS credentials on the GitHub repo:</p><ul><li><code>AWS&#95;ACCESS&#95;KEY&#95;ID</code> (must be named like that)</li><li><code>AWS&#95;SECRET&#95;ACCESS&#95;KEY</code> (must be named like that)</li><li><code>ECR&#95;REPO</code></li></ul><h2>AWS EC2</h2><p>This <a href='https://medium.com/appgambit/part-1-running-docker-on-aws-ec2-cbcf0ec7c3f8'>article</a> explained quite well how to setup docker in EC2 and pull image from ECR.</p><h3>IAM policy and role, Security group</h3><p>The UserData to install docker at first launch of the EC2 instance is the following:</p><pre><code class="bash">#! /bin/sh
# For Amazon linux 2022 &#40;might differ in 2023 but the principle remains&#41;
yum update -y
amazon-linux-extras install docker
service docker start
usermod -a -G docker ec2-user
chkconfig docker on
</code></pre><p>To allow the EC2 to pull from ECR we need to add an <code>IAM policy</code> and <code>IAM role</code>.</p><p>Let‚Äôs first create the policy <code>flybot-ECR-repo-access</code> :</p><pre><code class="bash">{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: &#91;
        {
            &quot;Sid&quot;: &quot;ListImagesInRepository&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Action&quot;: &#91;
                &quot;ecr:ListImages&quot;
            &#93;,
            &quot;Resource&quot;: &quot;arn:aws:ecr:region:acc:repository/flybot-website&quot;
        },
        {
            &quot;Sid&quot;: &quot;GetAuthorizationToken&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Action&quot;: &#91;
                &quot;ecr:GetAuthorizationToken&quot;
            &#93;,
            &quot;Resource&quot;: &quot;&#42;&quot;
        },
        {
            &quot;Sid&quot;: &quot;ManageRepositoryContents&quot;,
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Action&quot;: &#91;
                &quot;ecr:BatchCheckLayerAvailability&quot;,
                &quot;ecr:GetDownloadUrlForLayer&quot;,
                &quot;ecr:GetRepositoryPolicy&quot;,
                &quot;ecr:DescribeRepositories&quot;,
                &quot;ecr:ListImages&quot;,
                &quot;ecr:DescribeImages&quot;,
                &quot;ecr:BatchGetImage&quot;,
                &quot;ecr:InitiateLayerUpload&quot;,
                &quot;ecr:UploadLayerPart&quot;,
                &quot;ecr:CompleteLayerUpload&quot;,
                &quot;ecr:PutImage&quot;
            &#93;,
            &quot;Resource&quot;: &quot;arn:aws:ecr:region:acc:repository/flybot-website&quot;
        }
    &#93;
}
</code></pre><p>We then attached the policy <code>flybot-ECR-repo-access</code> to a role <code>flybot-ECR-repo-access-role</code></p><p>Finally, we attach the role <code>flybot-ECR-repo-access-role</code> to our EC2 instance.</p><p>We also need a <code>security group</code> to allow http(s) request and open our port 8123 for our <a href='https://github.com/clj-commons/aleph'>aleph</a> server.</p><p>We attached this SG to the EC2 instance as well.</p><h3>Run docker on EC2 instance and pull image from ECR</h3><p>Then inside the EC2 instance, we can pull the image from ECR and run it:</p><pre><code class="bash"># Login to ECR, this command will return a token
aws ecr get-login-password \
--region region \
| docker login \
--username AWS \
--password-stdin acc.dkr.ecr.region.amazonaws.com

# Pull image
docker pull acc.dkr.ecr.region.amazonaws.com/flybot-website:test

# Run image
docker run \
--rm \
-d \
-p 8123:8123 \
-v db-volume:/datalevin/prod/flybotdb \
-e OAUTH2=&quot;secret&quot; \
-e ADMIN&#95;USER=&quot;secret&quot; \
-e SYSTEM=&quot;{:http-port 8123, :db-uri \&quot;/datalevin/prod/flybotdb\&quot;, :oauth2-callback \&quot;https://www.flybot.sg/oauth/google/callback\&quot;}&quot; \
acc.dkr.ecr.region.amazonaws.com/flybot-website:test
</code></pre><h2>Load Balancers</h2><p>Even if we have one single EC2 instance running, there are several benefits we can get from AWS load balancers.</p><p>In our case, we have an Application Load Balancer (ALB) as target of a Network Load Balancer (NLB). Easily adding an ALB as target of NLB is a recent <a href='https://aws.amazon.com/blogs/networking-and-content-delivery/using-aws-lambda-to-enable-static-ip-addresses-for-application-load-balancers/'>feature</a> in AWS that allows us to combine the strength of both LBs.</p><h3>ALB</h3><p>The internal ALB purposes:</p><ul><li>redirect naked domain (flybot.sg) to sub domain (www.flybot.sg)</li><li>redirect http to https using the SSL certificates from AWS Certificate Manager (<code>ACM</code>)</li></ul><p>ACM allows us to requests certificates for <code>www.flybot.sg</code> and <code>flybot.sg</code> and attach them to the ALB rules to perform path redirection in our case. This is convenient as we do not need to install any ssl certificates or handle any redirects in the instance directly or change the code base.</p><h3>NLB</h3><p>Since the ALB has dynamic IPs, we cannot use it in our goDaddy <code>A</code> record for <code>flybot.sg</code>. One solution is to use AWS route53 because AWS added the possibility to register the ALB DNS name in a A record (which is not possible with external DNS managers). However, we already use goDaddy as DNS host and we don‚Äôt want to depend on route53 for that.</p><p>Another solution is to place an internet-facing NLB behind the ALB because NLB provides static IP.</p><p>ALB works at level 7 but NLB works at level 4.</p><p>Thus, we have for the NLB:</p><ul><li>TCP rule that forwards request to ALB on port 80 (for http)</li><li>TCP rules that forwards request on port 443 (for https)</li></ul><h3>Target group</h3><p>The target group is where the traffic from the load balancers is sent. We have 3 target groups.</p><ul><li>The first target group contains the EC2 instance in which the ALB forward request.</li><li>The second target group contains the ALB with the protocol TCP 80 in which the NLB forward http requests.</li><li>The third target group contains the ALB with the protocol TCP 443 in which the NLB forward https request.</li></ul><h3>DNS records</h3><p>Since the ELB is the internet-facing entry points, we use a <code>CNAME</code> record for <code>www</code> resolving to the ELB DNS name.</p><p>For the root domain <code>flybot.sg</code>, we use a <code>A</code> record for <code>@</code> resolving to the static IP of the ELB (for the AZ where the EC2 resides).</p><h2>Learn More</h2><p>You can have a look at the open-source repo: <a href='https://github.com/skydread1/flybot.sg'>skydread1/flybot.sg</a></p>]]></content:encoded></item><item><title>Datomic Setup examples: embedded, cassandra, docker.</title><link>https://www.loicblanchard.me/blog/datomic-setup-examples</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/datomic-setup-examples</guid><pubDate>Fri, 02 Dec 2022 08:16:25 +0000</pubDate><description>
How to run an embedded version of Datomic. How to run Datomic with a Cassandra cluster. How to run it in Docker.
</description><content:encoded><![CDATA[<h2>Introduction</h2><p>While working on <a href='http://flybot.sg'>flybot.sg</a> , I experimented with <code>datomic-free</code>, datomic <code>starter-pro</code> with Cassandra and datomic starter-pro with embedded storage.</p><h2>Rational</h2><p>You can read the rationale of Datomic from their <a href='https://docs.datomic.com/on-prem/getting-started/brief-overview.html'>on-prem documentation</a></p><p>Stuart Sierra explained very well how datomic works in the video <a href='https://www.youtube.com/watch?v=R6ObrDWTlYA'>Intro to Datomic</a>.</p><p>Basically, Datomic works as a layer on top of your underlying storage (in this case, we will use Cassandra db).</p><p>Your <code>application</code> and a Datomic <code>transactor</code> are contained in a <code>peer</code>. </p><p>The transactor is the process that controls inbounds, and coordinates persistence to the storage services.</p><p>The process acts as a single authority for inbound transactions. A single transactor process allows the to be ACID compliant and fully consistent.</p><p>The peer is the process that will query the persisted data.</p><p>Since Datomic leverages existing storage services, you can change persistent storage fairly easily.</p><h2>Datomic Starter Pro with Cassandra</h2><h3>Datomic pro starter version</h3><p>Datomic is closed-source and commercial.</p><p>You can see the different pricing models in the page <a href='https://www.datomic.com/get-datomic.html'>Get Datomic On-Prem</a>.</p><p>There are a few way to get started for free. The first one being to use the <a href='https://blog.datomic.com/2012/07/datomic-free-edition.html'>datomic-free</a> version which comes with in-mem database storage and local-storage transactor. You don‚Äôt need any license to use it so it is a good choice to get familiar with the datomic Clojure API.</p><p>Then, there is <code>datomic pro starter</code> renamed <code>datomic starter</code> which is free and maintained for 1 year. After the one year threshold, you won‚Äôt benefit from support and you won‚Äôt get new versions of Datomic. You need to register to Datomic to get the license key.</p><h3>Cassandra, Java and Python version caveats</h3><p>Datomic only support Cassandra up to version 3.x.x</p><p>Datomic start pro version of Cassandra at the time of writting: 3.7.1</p><p>Closest stable version of Cassandra: 3.11.10</p><p><strong>Problem 1: Datomic does not support java 11 so we have to have a java 8 version on the machine</strong></p><p>Solution: use <a href='https://github.com/jenv/jenv'>jenv</a> to manage multiple java version</p><pre><code class="bash"># jenv to manage java version
brew install jenv
echo 'export PATH=&quot;$HOME/.jenv/bin:$PATH&quot;' &gt;&gt; &#126;/.bash&#95;profile
echo 'eval &quot;$&#40;jenv init -&#41;&quot;' &gt;&gt; &#126;/.bash&#95;profile
# add cask version
brew tap homebrew/cask-versions
# install java 8 cask
brew install --cask adoptopenjdk8
# add java 11 &#40;current java version&#41; to jenv
jenv add &quot;$&#40;/usr/libexec/java&#95;home&#41;&quot;
# add java 8 to jenv
jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home
# update the ${JAVA&#95;HOME} everytim we change version
jenv enable-plugin export
#swith to java 8
jenv global 1.8
</code></pre><p><strong>Problem 2: cqlsh does not work with python3 with Cassandra running on java8</strong></p><p>Solution: download the python2 pkg directly from <a href='https://www.python.org/downloads/release/python-2718/'>python.org</a></p><p><strong>Problem 3: <code>brew install cassandra@3</code> triggers an execution error hard to debug</strong></p><p>Solution: download the tar.gz directly on <a href='https://www.apache.org/dyn/closer.lua/cassandra/3.11.14/apache-cassandra-3.11.14-bin.tar.gz'>apache.org</a></p><h3>Setup Cassandra locally and run start the transactor</h3><p>To test Cassandra and datomic locally, we can use the Test Cluster of Cassandra which comes up with only one node.</p><p>Datomic instruction for Cassandra <a href='https://docs.datomic.com/on-prem/overview/storage.html#cassandra'>here</a></p><pre><code class="bash"># Check if all the versions are ok
java -version
openjdk version &quot;1.8.0&#95;292&quot;
OpenJDK Runtime Environment &#40;AdoptOpenJDK&#41;&#40;build 1.8.0&#95;292-b10&#41;
OpenJDK 64-Bit Server VM &#40;AdoptOpenJDK&#41;&#40;build 25.292-b10, mixed mode&#41;
python2 -V
Python 2.7.18
cqlsh
Connected to Test Cluster at 127.0.0.1:9042.
&#91;cqlsh 5.0.1 | Cassandra 3.11.14 | CQL spec 3.4.4 | Native protocol v4&#93;
Use HELP for help.

# Start cassandra
cassandra -f

# ===========================================================
# in other terminal

# Only setup replica to 1 for the test cluster locally
# add datomic keyspace and table
cqlsh
CREATE KEYSPACE IF NOT EXISTS datomic WITH replication = {'class': 'SimpleStrategy', 'replication&#95;factor' : 1};
CREATE TABLE IF NOT EXISTS datomic.datomic
&#40;
  id text PRIMARY KEY,
  rev bigint,
  map text,
  val blob
&#41;;

# ===========================================================
# in other terminal

# start datomic transactor
# A sample of the cassandra transactor properties is provided in the datomic distribution samples.
# the documentation of datomic mentioned we should have a msg of the shape:
# System starter URI but I do not have URI but it seems to work nonetheless
cd datomic-pro-1.0.6527/
bin/transactor &#126;/workspaces/myproj/config/cassandra-transactor.properties
Launching with Java options -server -Xms1g -Xmx1g -XX:+UseG1GC -XX:MaxGCPauseMillis=50
System started

# ===========================================================
# in other terminal

# Test if the peer works properly on our localhost single node
bin/shell
Datomic Java Shell
Type Shell.help&#40;&#41;; for help.
datomic % uri = &quot;datomic:cass://localhost:9042/datomic.datomic/myproj&quot;;
&lt;datomic:cass://localhost:9042/datomic.datomic/myproj&gt;
datomic % Peer.createDatabase&#40;uri&#41;;
&lt;true&gt;
datomic % conn = Peer.connect&#40;uri&#41;;
&lt;{:unsent-updates-queue 0, :pending-txes 0, :next-t 1000, :basis-t 66, :index-rev 0, :db-id &quot;myproj-some-id-here&quot;}&gt;
</code></pre><p>It‚Äôs important to note that we do not add <code>ssl</code> in the database URI so we don‚Äôt have to deal with the <a href='https://docs.datomic.com/on-prem/overview/storage.html#troubleshooting'>KeyStore and TrustStore</a> (for local use only)</p><h3>Use Clojure API to create db and perform transactions</h3><p>Since the peer works using the datomic shell, we can confidently use the Clojure API from our code now.</p><p>We just need to add the datomic and Cassandra deps in the <code>deps.edn</code>:</p><pre><code class="clojure">;; deps.edn : versions are provided upon subscription to datomic-pro
com.datomic/datomic-pro                      {:mvn/version &quot;1.0.6527&quot;}
com.datastax.cassandra/cassandra-driver-core {:mvn/version &quot;3.1.0&quot;}
</code></pre><h2>Datomic Starter Pro with embedded storage</h2><p>In case of embedded DB, we only need to start a transactor and that‚Äôs it.</p><p>The URI to connect to the peer is of the shape:</p><pre><code class="clojure">&quot;datomic:dev://localhost:4334/myproj-db?password=my-secret&quot;
;; the password is the `storage-datomic-password` setup in the transactor properties.
</code></pre><h2>Datomic in docker container</h2><p>In case we want to run datomic in a container (and maybe having our app in another container), we can do the following:</p><ul><li>create DockerFile for our app</li><li>create DockerFile for Datomic Starter Pro (you could do the same with datomic-free)</li><li>create docker-compose file to run both the containers</li><li>update the transactors properties to be sure the app and transactor can communicate.</li></ul><h3>DockerFiles</h3><p>We assume that the app has its own DockerFile and run on port 8123 in this example.</p><p>Here is a DockerFile example to have Datomic running in a container:</p><pre><code class="docker">FROM clojure:lein-2.6.1-alpine

ENV DATOMIC&#95;VERSION 1.0.6527
ENV DATOMIC&#95;HOME /opt/datomic-pro-$DATOMIC&#95;VERSION
ENV DATOMIC&#95;DATA $DATOMIC&#95;HOME/data

RUN apk add --no-cache unzip curl

# Datomic Pro Starter as easy as 1-2-3
# 1. Create a .credentials file containing user:pass
# for downloading from my.datomic.com
ADD .credentials /tmp/.credentials

# 2. Make sure to have a config/ folder in the same folder as your
# Dockerfile containing the transactor property file you wish to use
RUN curl -u $&#40;cat /tmp/.credentials&#41; -SL https://my.datomic.com/repo/com/datomic/datomic-pro/$DATOMIC&#95;VERSION/datomic-pro-$DATOMIC&#95;VERSION.zip -o /tmp/datomic.zip \
  &amp;&amp; unzip /tmp/datomic.zip -d /opt \
  &amp;&amp; rm -f /tmp/datomic.zip

ADD config $DATOMIC&#95;HOME/config

WORKDIR $DATOMIC&#95;HOME
RUN echo DATOMIC HOME: $DATOMIC&#95;HOME

# 3. Provide a CMD argument with the relative path to the transactor.properties
VOLUME $DATOMIC&#95;DATA

EXPOSE 4334 4335 4336

CMD bin/transactor -Ddatomic.printConnectionInfo=true config/dev-transactor.properties
</code></pre><h3>Docker Compose</h3><p>Here is a <code>docker-compose.yml</code> we could use describing our app and datomic transactor containers</p><pre><code class="yaml">version: '3.0'
services:
  datomicdb:
    image: datomic-img
    hostname: datomicdb
    ports:
      - &quot;4336:4336&quot;
      - &quot;4335:4335&quot;
      - &quot;4334:4334&quot;
    volumes:
      - &quot;/data&quot;
  myprojapp:
    image: myproj-img
    ports:
      - &quot;8123:8123&quot;
    depends&#95;on:
      - datomicdb
</code></pre><p>Here are the commands to create the images and run 2 containers.</p><pre><code class="docker"># Create datomic transactor image
docker build -t datomic-img .

# Create app image
docker build -t myproj-img .

# run the 2 images in containers
docker-compose up
</code></pre><p>However, this will not work right away as we need to add a few configurations to the datomic transactor properties to make sure the app can communicate with the transactor.</p><h3>Transactors Properties</h3><p>Regarding the transactor properties (datomic provides a template for a transactor with Cassandra storage), when we use docker, we need to pay attention to 3 properties:</p><ul><li>The <code>localhost</code> is now 0.0.0.0</li><li><code>alt-host</code> must be added with the container name (or IP) or the container running the app.</li><li><code>storage-access</code> must be set to <code>remote</code></li></ul><p>Here are the difference between containerized and not containerized properties for a <code>dev-transactor</code>: </p><pre><code class="yaml"># If datomic not in container
protocol=dev
host=localhost
port=4334

# If datomic in container
protocol=dev
host=0.0.0.0
port=4334
alt-host=datomicdb
storage-access=remote
</code></pre><p>After updating the transactor properties, you should be able to see the app running on port 8123 and be able to perform transactions as expected.</p>]]></content:encoded></item><item><title>Pack, Push and Import Clojure to Unity</title><link>https://www.loicblanchard.me/blog/clojure-in-unity</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/clojure-in-unity</guid><pubDate>Fri, 22 Apr 2022 08:16:25 +0000</pubDate><description>
How to package a Compiled Clojure lib (With MAGIC compiler) to NuGet, push it to remote and import it to Unity.
</description><content:encoded><![CDATA[<h2>Prerequisites</h2><p>Your Clojure library is assumed to be already compiled to dotnet.</p><p>To know how to do this, refer to the article: <a href='https://www.loicblanchard.me/blog/port-clj-lib-to-clr'>Port your Clojure lib to the CLR with MAGIC</a></p><h2>Goal</h2><p>In this article, I will show you:</p><ul><li>how to package your lib to NuGet</li><li>push it in to your host repo</li><li>import in Unity in this article</li></ul><h2>Build the dlls with Nostrand</h2><p>Just use the command <code>nos dotnet/build</code> at the root of the Clojure project.</p><p>The dlls are by default generated in a <code>/build</code> folder.</p><h2>Dependency management</h2><p>A <code>.csproj</code> file (XML) must be added at the root of the Clojure project.</p><p>You can find an example here: <a href='https://github.com/skydread1/clr.test.check/blob/magic/clr.test.check.csproj'>clr.test.check.csproj</a></p><pre><code class="xml">&lt;Project Sdk=&quot;Microsoft.NET.Sdk&quot;&gt;
    &lt;PropertyGroup&gt;
        &lt;TargetFrameworks&gt;netstandard2.0&lt;/TargetFrameworks&gt;
    &lt;/PropertyGroup&gt;
    &lt;PropertyGroup&gt;
        &lt;NuspecFile&gt;clr.test.check.nuspec&lt;/NuspecFile&gt;
        &lt;RestoreAdditionalProjectSources&gt;
            https://api.nuget.org/v3/index.json
        &lt;/RestoreAdditionalProjectSources&gt;
    &lt;/PropertyGroup&gt;
&lt;/Project&gt;
</code></pre><p>There is no need to add References as they were already built by Nostrand in the <code>/build</code> folder.</p><p>Note the <code>NuspecFile</code> that is required to use the nuspec.</p><h2>Package Manager</h2><p>A <code>.nuspec</code> file (XML) must be added at the root of the Clojure project.</p><p>The <code>references</code> are the references to the dlls in <code>/build</code>.</p><p>You can find an example here: <a href='https://github.com/skydread1/clr.test.check/blob/magic/clr.test.check.nuspec'>clr.test.check.nuspec</a></p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;package&gt;
    &lt;metadata&gt;
        &lt;id&gt;clr.test.check&lt;/id&gt;
        &lt;version&gt;1.1.1&lt;/version&gt;
        &lt;title&gt;clr.test.check&lt;/title&gt;
        &lt;authors&gt;skydread1&lt;/authors&gt;
        &lt;description&gt;Contains the core references for the Clojure lib test.check.&lt;/description&gt;
        &lt;repository type=&quot;git&quot; url=&quot;https://github.com/skydread1/clr.test.check&quot; /&gt;
        &lt;dependencies&gt;
            &lt;group targetFramework=&quot;netstandard2.0&quot;&gt;&lt;/group&gt;
        &lt;/dependencies&gt;
    &lt;/metadata&gt;
    &lt;files&gt;
        &lt;file src=&quot;build\&#42;.clj.dll&quot; target=&quot;lib\netstandard2.0&quot; /&gt;
    &lt;/files&gt;
&lt;/package&gt;
</code></pre><p>The <code>dependency</code> tag is required to indicate the targeted framework.</p><p>The <code>file</code> (using a wild card to avoid adding the files one by one) is required to add the dlls files that will be available for the consumer. So the target must be <code>lib\TFM</code>.</p><p>In our case, Unity recommends to use <code>netstandard2.0</code> so our target is <code>lib\netstandard2.0</code>.</p><h2>GitHub/GitLab local config</h2><p>To push the package to a git host, one of the most convenient way is to have a <code>nuget.config</code> (XML) locally at the root of the project.</p><h3>The nuget.config for GitHub</h3><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;configuration&gt;
    &lt;packageSources&gt;
        &lt;clear /&gt;
        &lt;add key=&quot;github&quot; value=&quot;https://nuget.pkg.github.com/skydread1/index.json&quot; /&gt;
    &lt;/packageSources&gt;
    &lt;packageSourceCredentials&gt;
        &lt;github&gt;
            &lt;add key=&quot;Username&quot; value=&quot;skydread1&quot; /&gt;
            &lt;add key=&quot;ClearTextPassword&quot; value=&quot;PAT&quot; /&gt;
        &lt;/github&gt;
    &lt;/packageSourceCredentials&gt;
&lt;/configuration&gt;
</code></pre><p>In order to push a Package to a <code>Package Registry</code> to your GitHub project repo, you will need to create a <strong>PAT</strong> (Personal Access Token) with the <code>write:packages</code> ,<code>:read:packages</code> and <code>delete:packages</code> permissions.</p><p>Replace Username value by your Github username</p><p>Replace Token value by your newly created access token</p><p>Replace the repo URL by the path to your GitHub <strong>account page</strong> (not the repo).</p><p><em>Note: Do not push your config in GitHub as it contains sensitive info (your PAT), it is just for local use.</em></p><h3>The nuget.config for GitLab</h3><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;configuration&gt;
    &lt;packageSources&gt;
        &lt;clear /&gt;
        &lt;add key=&quot;gitlab&quot; value=&quot;https://sub.domain.sg/api/v4/projects/777/packages/nuget/index.json&quot; /&gt;
    &lt;/packageSources&gt;
    &lt;packageSourceCredentials&gt;
        &lt;gitlab&gt;
            &lt;add key=&quot;Username&quot; value=&quot;deploy-token-name&quot; /&gt;
            &lt;add key=&quot;ClearTextPassword&quot; value=&quot;deploy-token-value&quot; /&gt;
        &lt;/gitlab&gt;
    &lt;/packageSourceCredentials&gt;
&lt;/configuration&gt;
</code></pre><p>In order to push a Package to a <code>Package Registry</code> to your GitLab project repo, you will need to create a <strong>deploy token</strong> (not access token) with the <code>read&#95;package&#95;registry</code> and <code>write&#95;package&#95;registry</code> permissions.</p><p>Replace Username value by your token username</p><p>Replace Token value by your newly created deploy token</p><p>Replace the domain (for private server) and project number in the GitLab URL. (don‚Äôt forget the index.json at the end)</p><p><em>Note: Do not push your config in GitLab as it contains sensitive info (your deploy token), it is just for local use.</em></p><h2>Pack and Push nuget packages with Nostrand</h2><p>At the root of the project, the <code>dotnet.clj</code> contains the convenient function to be used with <a href='https://github.com/nasser/nostrand'>nasser/nostrand</a>.</p><p>You can find an example here: <a href='https://github.com/skydread1/clr.test.check/blob/magic/dotnet.clj'>dotnet.clj</a></p><p>We added to our Clojure library a convenient function to avoid having to manually use the dotnet commands, you can just run at the root at the Clojure directory:</p><pre><code class="bash">nos dotnet/nuget-push
</code></pre><p>This will create the nuget code package <code>.nupkg</code> file in the folder <code>bin/Release</code>. the name is the package name and the version such as <code>clr.test.check.1.1.1.nupkg</code>.</p><p>It will then push it to either Gitlab or Github depending on the host using the credentials in <code>nuget.config</code>.</p><p>It is equivalent to the 2 dotnet commands:</p><pre><code class="bash">dotnet pack --configuration Release
dotnet nuget push &quot;bin/Release/clr.test.check.1.1.1.nupkg&quot; --source &quot;github&quot;
</code></pre><p><strong>Note</strong>: for a Clojure project, you can let the default option for the packing. There is no need to build in theory as we already have our dlls ready in our <code>/build</code> folder. The <code>dotnet build</code> will just create a unique dll with the name of your library that you can just ignore.</p><h2>Download nuget Packages</h2><p>Using package references is the new way of doing this but it does not work with Unity.</p><h3>Import nuget packages to a regular C# project</h3><p>The new way of importing the nuget packages is to use the <code>PackageReference</code> tag directly in the <code>.csproj</code> file such as:</p><pre><code class="bash">&lt;PackageReference Include=&quot;Sitecore.Kernel&quot; Version=&quot;12.0.&#42;&quot; /&gt;
</code></pre><p>But this method only works if you are using the <code>.csproj</code> file which we don‚Äôt use in Unity as we use the <code>manifest.json</code>.</p><h2>Import nuget packages to a Unity project</h2><p>Unity uses a json file in <code>Packages/manifest.json</code> to download deps. However it does not work for nuget packages.</p><p>There is no <code>.csproj</code> at the root so we cannot use the method above, and all the other underlying <code>csproj</code> are generated by Unity so we cannot change them.</p><p>The only choice we have is to use the old way of importing the nuget packages which is to use a <code>packages.config</code> and then use the command <code>nuget restore</code> to fetch the packages last versions.</p><p>So we need to add 2 config files in our root of our Unity project:</p><ul><li><code>nuget.config</code> : github/gitlab credentials</li><li><code>packages.config</code> : packages name and their version/target</li></ul><h3>nuget.config</h3><p>In order to fetch all the packages at once using <code>nuget restore</code>, we need to add locally the <code>nuget.config</code> with the different sources and credentials.</p><p>So to restore our GitHub and GitLab packages from our example, we use the following <code>nuget.restore</code>:</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;configuration&gt;
    &lt;config&gt;
	      &lt;add key=&quot;repositoryPath&quot; value=&quot;Assets/ClojureLibs&quot; /&gt;
	  &lt;/config&gt;
    &lt;packageSources&gt;
        &lt;clear /&gt;
        &lt;add key=&quot;gitlab&quot; value=&quot;https://sub.domain.sg/api/v4/projects/777/packages/nuget/index.json&quot; /&gt;
        &lt;add key=&quot;github&quot; value=&quot;https://nuget.pkg.github.com/skydread1/index.json&quot; /&gt;
    &lt;/packageSources&gt;
    &lt;packageSourceCredentials&gt;
        &lt;gitlab&gt;
            &lt;add key=&quot;Username&quot; value=&quot;deploy-token-name&quot; /&gt;
            &lt;add key=&quot;ClearTextPassword&quot; value=&quot;deploy-token-value&quot; /&gt;
        &lt;/gitlab&gt;
        &lt;github&gt;
            &lt;add key=&quot;Username&quot; value=&quot;skydread1&quot; /&gt;
            &lt;add key=&quot;ClearTextPassword&quot; value=&quot;PAT&quot; /&gt;
        &lt;/github&gt;
    &lt;/packageSourceCredentials&gt;
&lt;/configuration&gt;
</code></pre><p>The <code>repositoryPath</code> allows us to get our packages in a specific directory. In our case, we put it in <code>Assets/ClojureLibs</code> (it needs to be in the <code>Asset</code> dir anywhere)</p><h3>packages.config</h3><p>To tell Unity which packages to import while running <code>nuget restore</code>, we need to provide the <code>packages.config</code>. Here is the config in our example:</p><pre><code class="bash">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;packages&gt;
  &lt;package id=&quot;Magic.Unity&quot; version=&quot;1.0.0&quot; targetFramework=&quot;netstandard2.0&quot; /&gt;
  &lt;package id=&quot;my-private-proj&quot; version=&quot;1.0.0&quot; targetFramework=&quot;netstandard2.0&quot; /&gt;
  &lt;package id=&quot;clr.test.check&quot; version=&quot;1.1.1&quot; targetFramework=&quot;netstandard2.0&quot; /&gt;
&lt;/packages&gt;
</code></pre><h3>Magic.Unity</h3><p>To run clojure in Unity, you need <a href='https://github.com/nasser/Magic.Unity'>Magic.Unity</a>. It is a the runtime for Clojure compiles with Magic in Unity.</p><p>Note the <code>Magic.Unity</code> in the <code>packages.config</code> above. Magic.Unity has its own nuget package deployed the same way as you would deploy a Clojure library, so you import it along side your nuget packages with your compiles clojure libs.</p><h3>nuget restore</h3><p>Once you have the github/gitlab credentials ready in <code>nuget.config</code> and the packages and their version/target listed in <code>packages.config</code>, you can run the command <code>nuget restore</code> at the root of the unity project.</p><p>If running <code>nuget restore</code> do not fetch the last version, it is because it is using the local cache. In this case you need to force restore using those <a href='https://docs.microsoft.com/en-us/nuget/consume-packages/package-restore#force-restore-from-package-sources'>commands</a>.</p><p>Most of the time, ignoring the cache is fixing this issue:</p><pre><code class="bash">nuget restore -NoCache
</code></pre><p>Here is the packages tree of our project for instance:</p><pre><code class="bash">&#126;/workspaces/unity-projects/my-proj:
.
‚îú‚îÄ‚îÄ clr.test.check-legacy.1.1.1
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ clr.test.check-legacy.1.1.1.nupkg
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ lib
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ netstandard2.0
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ clojure.test.check.clj.dll
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ clojure.test.check.clojure&#95;test.assertions.clj.dll
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ clojure.test.check.clojure&#95;test.clj.dll
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ clojure.test.check.generators.clj.dll
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ clojure.test.check.impl.clj.dll
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ clojure.test.check.random.clj.dll
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ clojure.test.check.results.clj.dll
‚îÇ¬†¬†         ‚îî‚îÄ‚îÄ clojure.test.check.rose&#95;tree.clj.dll
‚îú‚îÄ‚îÄ my-private-lib.1.0.0
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ my-private-lib.1.0.0.nupkg
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ lib
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ netstandard2.0
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ domain.my&#95;prate&#95;lib.core.clj.dll
‚îÇ¬†¬†  ¬†¬†     ‚îî‚îÄ‚îÄ domain.my&#95;prate&#95;lib.core.utils.clj.dll
</code></pre><p>Finally, You can add Magic.Unity (runtime for magic inside Unity) in the manifest.json like so:</p><pre><code class="json">{
  &quot;dependencies&quot;: {
	  ...,
    &quot;sr.nas.magic.unity&quot;: &quot;https://github.com/nasser/Magic.Unity.git&quot;
	}
}
</code></pre><h2>Conclusion</h2><p>Once you have the proper required config files ready, you can use <code>Nostrand</code> to Build your dlls:</p><pre><code>nos dotnet/build
</code></pre><p>Pack your dlls in a nuget package and push to a remote host:</p><pre><code>nos dotnet/nuget-push
</code></pre><p>Import your packages in Unity:</p><pre><code>nuget restore
</code></pre><p><code>Magic.Unity</code> is the Magic runtime for Unity and is already nuget packaged on its public repo</p>]]></content:encoded></item><item><title>Fun-Map: a solution to deps injection in Clojure</title><link>https://www.loicblanchard.me/blog/fun-map</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/fun-map</guid><pubDate>Tue, 12 Apr 2022 08:16:25 +0000</pubDate><description>
Rational of `fun-map`, including the benefit of the `life-cycle-map` as dependency injection system.
</description><content:encoded><![CDATA[<h2>Context</h2><p>The Lasagna stack library <a href='https://github.com/robertluo/fun-map'>fun-map</a> by <a href='https://github.com/robertluo'>@robertluo</a> blurs the line between identity, state and function. As a results, it is a very convenient tool to define <code>system</code> in your applications by providing an elegant way to perform associative dependency injections.</p><h2>Goal</h2><p>In this document, I will show you the benefit of <code>fun-map</code>, and especially the <code>life-cycle-map</code> as dependency injection system.</p><h2>Rational</h2><h3>Managing state</h3><p>In any kind of programs, we need to manage the state. In Clojure, we want to keep the mutation parts of our code as isolated and minimum as possible. The different components of our application such as the db connections, queues or servers for instance are mutating the world and sometimes need each other to do so. The talk <a href='https://www.youtube.com/watch?v=13cmHf_kt-Q'>Components Just Enough Structure</a> by Stuart Sierra explains this dependency injection problem very well and provides a Clojure solution to this problem with the library <a href='https://github.com/stuartsierra/component'>component</a>.</p><p><a href='https://github.com/robertluo/fun-map'>fun-map</a> is another way of dealing with inter-dependent components. In order to understand why <code>fun-map</code> is very convenient, it is interesting to look at other existing solutions first.</p><h3>Component</h3><p>Let‚Äôs first have a look at existing solution to deal with life cycle management of components in Clojure, especially the Component library which is a very good library to provide a way to define systems.</p><p>In the Clojure word, we have stateful components (atom, channel etc) and we don‚Äôt want it to be scattered in our code without any clear way to link them and also know the order of which to start these external resources. </p><p>The <code>component</code> of the library  <a href='https://github.com/stuartsierra/component'>component</a> is just a record that implements a <code>Lifecycle</code> protocol to properly start and stop the component. As a developer, you just implement the <code>start</code> and <code>stop</code> methods of the protocol for each of your components (DB, server or even domain model).</p><p>A DB component could look like this for instance</p><pre><code class="clojure">&#40;defrecord Database &#91;host port connection&#93;
  component/Lifecycle
  &#40;start &#91;component&#93;
    &#40;let &#91;conn &#40;connect-to-database host port&#41;&#93;
      &#40;assoc component :connection conn&#41;&#41;&#41;
  &#40;stop &#91;component&#93;
    &#40;.close connection&#41;
    &#40;assoc component :connection nil&#41;&#41;&#41;
</code></pre><p>All these components are then combined together in a <code>system</code> map that just bounds a keyword to each component. A system is a component that has its own start/stop implementation that is responsible to start all components in dependency order and shut them down in reverse order.</p><p>If a component has dependencies on other components, they are then associated to the system and started first. Since each component returns another state of the system; after all components are started, their return values are assoc back to the system.</p><p>Here is an example of a system with 3 components. The <code>app</code> components depends on the <code>db</code> and <code>scheduler</code> components so they will be started first:</p><pre><code class="clojure">&#40;defn system &#91;config-options&#93;
  &#40;let &#91;{:keys &#91;host port&#93;} config-options&#93;
    &#40;component/system-map
      :db &#40;new-database host port&#41;
      :scheduler &#40;new-scheduler&#41;
      :app &#40;component/using
             &#40;example-component config-options&#41;
             {:database  :db
              :scheduler :scheduler}&#41;&#41;&#41;&#41;
</code></pre><p>So, in the above example, <code>db</code> and <code>scheduler</code> have been injected to <code>app</code>. Stuart Sierra mentioned that contrary to <code>constructor</code> injections and <code>setter</code> injections OOP often use, we could refer this component injections (immutable map) as <code>associative</code> injections.</p><p>This is very convenient way to adapt a system to other different situations such as testing for instance. You could just assoc to an in-memory DB and a simplistic schedular in a test-system to run some tests:</p><pre><code class="clojure">&#40;defn test-system
	&#91;...&#93;
	&#40;assoc &#40;system some-config&#41;
		:db &#40;test-db&#41;
		:scheduler &#40;test-scheduler&#41;&#41;&#41;

;; then we can call &#40;start test-system&#41; to start all components in deps order.
</code></pre><p>Thus, you can isolate what you want to test and even run tests in parallel. So, it is more powerful than <code>with-redefs</code> and <code>binding</code> because it is not limited by time. Your tests could replace a big portion of your logic quite easily instead of individual vars allowing us to decouple the tests from the rest of the code.</p><p>Finally, we do not want to pass the whole system to every function in all namespaces. Instead, the components library allows you to specify just the component.</p><h4>Limitations</h4><p>However, there are some limitations to this design, the main ones being:</p><ul><li><code>stuartsierra/component</code> is a whole app buy-in. Your entire app needs to follow this design to get all the benefits from it.</li><li>It is not easy to visually inspect the whole system in the REPL</li><li>cannot start just a part of the system</li></ul><h4>Other approaches</h4><p>Other libraries were created as replacement of component such as <a href='https://github.com/tolitius/mount'>mount</a> and <a href='https://github.com/weavejester/integrant'>integrant</a>.</p><ul><li>Mount highlights their differences with Component in <a href='https://github.com/tolitius/mount/blob/master/doc/differences-from-component.md#differences-from-component'>here</a>.</li><li>Integrant highlights their differences with Component in <a href='https://github.com/weavejester/integrant/blob/master/README.md#rationale'>here</a>.</li></ul><h2>Fun-map</h2><p><a href='https://github.com/robertluo/fun-map'>fun-map</a> is yet another replacement of <a href='https://github.com/stuartsierra/component'>component</a>, but it does more than just providing state management.</p><p>The very first goal of <code>fun-map</code> is to blur the line between identity, state and function, but in a good way. <code>fun-map</code> combines the idea of <a href='https://github.com/originrose/lazy-map'>lazy-map</a> and <a href='https://github.com/plumatic/plumbing'>plumbing</a> to allow lazy access to map values regardless of the types or when these values are accessed. </p><h3>Wrappers</h3><p>In order to make the map‚Äôs values accessible on demand regardless of the type (delay, future, atom etc), map‚Äôs value arguments are wrapped to encapsulate the way the underlying values are accessed and return the values as if they were just data in the first place.</p><p>For instance:</p><pre><code class="clojure">&#40;def m &#40;fun-map {:numbers &#40;delay &#91;3 4&#93;&#41;}&#41;&#41;

m
;=&gt; {:numbers &#91;3 4&#93;}

&#40;apply &#42; &#40;:numbers m&#41;&#41;
;=&gt; 12

;; the delay will be evaluated just once
</code></pre><p>You can see that the user of the map is not impacted by the <code>delay</code> and only see the deref value as if it were just a vector in the first place.</p><h4>Associative dependency injections</h4><p>Similar to what we discussed regarding how the <a href='https://github.com/stuartsierra/component'>component</a> library assoc dependencies in order, fun-map as a wrapper macro <code>fk</code> to use other <code>:keys</code> as arguments of their function.</p><p>Let‚Äôs have a look at an example of <code>fun-map</code>:</p><pre><code class="clojure">&#40;def m &#40;fun-map {:numbers &#91;3 4&#93;
                 :cnt     &#40;fw {:keys &#91;numbers&#93;}
                              &#40;count numbers&#41;&#41;
                 :average &#40;fw {:keys &#91;numbers cnt&#93;}
                              &#40;/ &#40;reduce + 0 numbers&#41; cnt&#41;&#41;}&#41;&#41;
</code></pre><p>In the fun-map above, you can see that the key <code>:cnt</code> takes for argument the value of the key <code>:numbers</code>. The key <code>:average</code> takes for arguments the values of the key <code>:numbers</code> and <code>:cnt</code>.</p><p>Calling the <code>:average</code> key will first call the keys it depends on, meaning <code>:cnt</code> and <code>:number</code> then call the <code>:average</code> and returns the results:</p><pre><code class="clojure">&#40;:average m&#41;
;=&gt; 7/2
</code></pre><p>We recognize the same dependency injections process highlighted in the Component section.</p><p>Furthermore, fun-map provides a convenient wrapper <code>fnk</code> macro to destructure directly the keys we want to focus on:</p><pre><code class="clojure">&#40;def m &#40;fun-map {:numbers &#91;3 4&#93;
                 :cnt     &#40;fnk &#91;numbers&#93;
                                &#40;count numbers&#41;&#41;
                 :average &#40;fnk &#91;numbers cnt&#93;
                               &#40;/ &#40;reduce + 0 numbers&#41; cnt&#41;&#41;}&#41;&#41;
</code></pre><p>As explained above, we could add some more diverse values, it wouldn‚Äôt be perceived by the user of the map:</p><pre><code class="clojure"> &#40;def m &#40;fun-map {:numbers  &#40;delay &#91;3 4&#93;&#41;
                  :cnt      &#40;fnk &#91;numbers&#93;
                                 &#40;count numbers&#41;&#41;
                  :multiply &#40;fnk &#91;numbers&#93;
                                 &#40;atom &#40;apply &#42; numbers&#41;&#41;&#41;
                  :average  &#40;fnk &#91;numbers cnt&#93;
                                 &#40;/ &#40;reduce + 0 numbers&#41; cnt&#41;&#41;}&#41;&#41;

&#40;:multiply m&#41;
;=&gt; 12

m
;=&gt; {:numbers &#91;3 4&#93; :cnt 2 :multiply 12 :average 7/2}
</code></pre><h3>System</h3><h4>Life Cycle Map</h4><p>Wrappers take care of getting other keys‚Äôs values (with eventual options we did not talk about so far). However, to get the life cycle we describe in the Component library section, we still need a way to</p><ul><li>start each underlying values (components) in dependency order (other keys)</li><li>close each underlying values in reverse order of their dependencies</li></ul><p>fun-map provides a <code>life-cycle-map</code> that allows us to specify the action to perform when the component is getting started/closed via the <code>closeable</code>.</p><ul><li><code>touch</code> start the system, meaning it injects all the dependencies in order. the first argument of <code>closeable</code> (eventually deref in case it is a delay or atom etc) is returned as value of the key.</li><li><code>halt!</code> close the system, meaning it executes the second argument of <code>closeable</code> which is a function taking no param. It does so in reverse order of the dependencies</li></ul><p>Here is an example:</p><pre><code class="clojure">&#40;def system
  &#40;life-cycle-map ;; to support the closeable feature
   {:a &#40;fnk &#91;&#93;
            &#40;closeable
             100 ;; 1&#41; returned at touch
             #&#40;println &quot;a closed&quot;&#41; ;; 4&#41; evaluated at halt!
             &#41;&#41;
    :b &#40;fnk &#91;a&#93;
            &#40;closeable
             &#40;inc a&#41; ;; 2&#41; returned at touch
             #&#40;println &quot;b closed&quot;&#41; ;; 3&#41; evaluated at halt!
             &#41;&#41;}&#41;&#41;

&#40;touch system1&#41;
;=&gt; {:a 100, :b 101}

&#40;halt! system1&#41;
;=&gt; b closed
;   a closed
;   nil
</code></pre><p><code>closeable</code> takes 2 params:</p><ul><li>value returned when we call the key of the fun-map.</li><li>a no-arg function evaluated in reverse order of dependencies.</li></ul><h4>Testing</h4><p>Same as for Component, you can easily dissoc/assoc/merge keys in your system for testing purposes. You need to be sure to build your system before <code>touch</code>.</p><pre><code class="clojure">&#40;def test-system
  &#40;assoc system :a &#40;fnk &#91;&#93;
                        &#40;closeable
                         200
                         #&#40;println &quot;a closed v2&quot;&#41;&#41;&#41;&#41;&#41;

&#40;touch test-system&#41;
;=&gt; {:a 200, :b 201}

&#40;halt! test-system&#41;
;=&gt; b closed
;   a closed v2
;   nil
</code></pre><p>fun-map also support other features such as function call tracing, value caching or lookup for instance. More info in the readme.</p><h2>Fun-Map applied to flybot.sg</h2><p>To see Fun Map in action, refer to the doc <a href='https://www.loicblanchard.me/blog/fun-map-applied-to-flybot'>Fun-Map applied to flybot.sg</a>.</p>]]></content:encoded></item><item><title>Lasagna Pull: Precisely select from deep nested data</title><link>https://www.loicblanchard.me/blog/lasagna-pull</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/lasagna-pull</guid><pubDate>Tue, 12 Apr 2022 08:16:25 +0000</pubDate><description>
Rational of flybot-sg/lasagna-pull library: precisely select from deep data structure in Clojure.
</description><content:encoded><![CDATA[<h2>Context</h2><p><a href='https://github.com/flybot-sg/lasagna-pull'>flybot-sg/lasagna-pull</a> by <a href='https://github.com/robertluo'>@robertluo</a> aims at precisely select from deep data structure in Clojure.</p><h2>Goal</h2><p>In this document, I will show you the benefit of <code>pull-pattern</code> in pulling nested data.</p><h2>Rational</h2><p>In Clojure, it is very common to have to precisely select data in nested maps. the Clojure core <code>select-keys</code> and <code>get-in</code> functions do not allow to easily select in deeper levels of the maps with custom filters or parameters.</p><p>One of the libraries of the <code>lasagna-stack</code> is <a href='https://github.com/flybot-sg/lasagna-pull'>flybot-sg/lasagna-pull</a>. It takes inspiration from the <a href='https://docs.datomic.com/on-prem/query/pull.html'>datomic pull API</a> and the library <a href='https://github.com/redplanetlabs/specter'>redplanetlabs/specter</a>.</p><p><code>lasagna-pull</code> aims at providing a clearer pattern than the datomic pull API.</p><p>It also allows the user to add options on the selected keys (filtering, providing params to values which are functions etc). It supports less features than the <code>specter</code> library but the syntax is more intuitive and covers all major use cases you might need to select the data you want.</p><p>Finally, a <a href='https://github.com/metosin/malli'>metosin/malli</a> schema can be provided to perform data validation directly using the provided pattern. This allows the client to prevent unnecessary pulling if the pattern does not match the expected shape (such as not providing the right params to a function, querying the wrong type etc).</p><h2>A query language to select deep nested structure</h2><p>Selecting data in nested structure is made intuitive via a pattern that describes the data to be pulled following the shape of the data.</p><h3>Simple query cases</h3><p>Here are some simple cases to showcase the syntax:</p><ul><li>query a map<pre><code class="clojure">&#40;require '&#91;sg.flybot.pullable :as pull&#93;&#41;

&#40;&#40;pull/query '{:a ? :b {:b1 ?}}&#41;
 {:a 1 :b {:b1 2 :b2 3}}&#41;
;=&gt; {&amp;? {:a 1, :b {:b1 2}}}
</code></pre></li><li>query a sequence of maps<pre><code class="clojure">&#40;&#40;pull/query '&#91;{:a ? :b {:b1 ?}}&#93;&#41;
 &#91;{:a 1 :b {:b1 2 :b2 3}}
   {:a 2 :b {:b1 2 :b2 4}}&#93;&#41;
;=&gt; {&amp;? &#91;{:a 1, :b {:b1 2}} {:a 2, :b {:b1 2}}&#93;}
</code></pre></li><li>query nested sequences and maps<pre><code class="clojure">&#40;&#40;pull/query '&#91;{:a ?
                :b &#91;{:c ?}&#93;}&#93;&#41;
 &#91;{:a 1 :b &#91;{:c 2}&#93;}
  {:a 11 :b &#91;{:c 22}&#93;}&#93;&#41;
;=&gt; {&amp;? &#91;{:a 1, :b &#91;{:c 2}&#93;} {:a 11, :b &#91;{:c 22}&#93;}&#93;}
</code></pre></li></ul><p>Let‚Äôs compare datomic pull and lasagna pull query with a simple example:</p><ul><li>datomic pull<pre><code class="clojure">&#40;def sample-data
  &#91;{:a 1 :b {:b1 2 :b2 3}}
   {:a 2 :b {:b1 2 :b2 4}}&#93;&#41;

&#40;pull ?db
      &#91;:a {:b &#91;:b1&#93;}&#93;
      sample-data&#41;
</code></pre></li><li>Lasagna pull<pre><code class="clojure">&#40;&#40;pull/query '&#91;{:a ? :b {:b1 ?}}&#93;&#41;
 sample-data&#41;
;=&gt; {&amp;? &#91;{:a 1, :b {:b1 2}} {:a 2, :b {:b1 2}}&#93;}
</code></pre></li></ul><p>A few things to note</p><ul><li>lasagna-pull uses a map to query a map and surround it with a vector to query a sequence which is very intuitive to use.</li><li><code>?</code> is just a placeholder on where the value will be after the pull.</li><li>lasagna-pull returns a map with your pulled data in a key <code>&amp;?</code>.</li></ul><h3>Query specific keys</h3><p>You might not want to fetch the whole path down to a leaf key, you might want to query that key and store it in a dedicated var. It is possible to do this by providing a var name after the placeholder <code>?</code> such as <code>?a</code> for instance. The key <code>?a</code> will then be added to the result map along side the <code>&amp;?</code> that contains the whole data structure.</p><p>Let‚Äôs have a look at an example.</p><p>Let‚Äôs say we want to fetch specific keys in addition to the whole data structure:</p><pre><code class="clojure">&#40;&#40;pull/query '{:a ?a
               :b {:b1 ?b1 :b2 ?}}&#41;
 {:a 1 :b {:b1 2 :b2 3}}&#41;
; =&gt; {?&amp;  {:a 1 :b {:b1 2 :b2 3}} ;; all nested data structure
;     ?a  1 ;; var a
;     ?b1 2 ;; var b1
    }
</code></pre><p>The results now contain the logical variable we selected via <code>?a</code> and <code>?b1</code>. Note that the <code>:b2</code> key has just a <code>?</code> placeholder so it does not appear in the results map keys.</p><p>It works also for sequences:</p><pre><code class="clojure">;; logical variable for a sequence
&#40;&#40;pull/query '{:a &#91;{:b1 ?} ?b1&#93;}&#41;
 {:a &#91;{:b1 1 :b2 2} {:b1 2} {}&#93;}&#41;
;=&gt; {?b1 &#91;{:b1 1} {:b1 2} {}&#93;
;    &amp;?  {:a &#91;{:b1 1} {:b1 2} {}&#93;}}
</code></pre><p>Note that <code>'{:a &#91;{:b1 ?b1}&#93;}</code> does not work because the logical value cannot be the same for all the <code>b1</code> keys:</p><pre><code class="clojure">&#40;&#40;pull/query '{:a &#91;{:b1 ?b1}&#93;}&#41;
 {:a &#91;{:b1 1 :b2 2} {:b1 2} {}&#93;}&#41;
;=&gt; {&amp;? {:a &#91;{:b1 1} nil nil&#93;}} ;; not your expected result
</code></pre><h2>A query language to select structure with params and filters</h2><p>Most of the time, just selecting nested keys is not enough. We might want to select the key if certain conditions are met, or even pass a parameter if the value of the key is a function so we can run the function and get the value.</p><p>With library like <a href='https://github.com/redplanetlabs/specter'>redplanetlabs/specter</a>, you have different possible transformations using diverse <a href='https://github.com/redplanetlabs/specter/wiki/List-of-Macros'>macros</a> which is an efficient way to select/transform data. The downside is that it introduces yet another syntax to get familiar with.</p><p><code>lasagna-pull</code> supports most of the features at a key level.</p><p>Instead of just providing the key you want to pull in the pattern, you can provide a list with the key as first argument and the options as the rest of the list.</p><p>The transformation is done at the same time as the selection, the pattern can be enhanced with options:</p><ul><li>not found<pre><code class="clojure">&#40;&#40;pull/query '{&#40;:a :not-found ::not-found&#41; ?}&#41; {:b 5}&#41;
;=&gt; {&amp;? {:a :user/not-found}}
</code></pre></li><li>when<pre><code class="clojure">&#40;&#40;pull/query {&#40;:a :when even?&#41; '?}&#41; {:a 5}&#41;
;=&gt; {&amp;? {}} ;; empty because the value of :a is not even
</code></pre></li><li>with</li></ul><p>If the value of a query is a function, using <code>:with</code> option can invoke it and returns the result instead:</p><pre><code class="clojure">&#40;&#40;pull/query '{&#40;:a :with &#91;5&#93;&#41; ?}&#41; {:a #&#40;&#42; % 2&#41;}&#41;
;=&gt; {&amp;? {:a 10}} ;; the arg 5 was given to #&#40;&#42; % 2&#41; and the result returned
</code></pre><ul><li>batch</li></ul><p>Batched version of :with option:</p><pre><code class="clojure">&#40;&#40;pull/query '{&#40;:a :batch &#91;&#91;5&#93; &#91;7&#93;&#93;&#41; ?}&#41; {:a #&#40;&#42; % 2&#41;}&#41;
;=&gt; {&amp;? {:a &#40;10 14&#41;}}
</code></pre><ul><li>seq</li></ul><p>Apply to sequence value of a query, useful for pagination:</p><pre><code class="clojure">&#40;&#40;pull/query '&#91;{:a ? :b ?} ? :seq &#91;2 3&#93;&#93;&#41; &#91;{:a 0} {:a 1} {:a 2} {:a 3} {:a 4}&#93;&#41;
;=&gt; {&amp;? &#40;{:a 2} {:a 3} {:a 4}&#41;}
</code></pre><p>As you can see with the different options above, the transformations are specified within the selected keys. Unlike specter however, we do not have a way to apply transformation to all the keys for instance.</p><h2>Pattern validation with Malli schema</h2><p>We can optionally provide a <a href='https://github.com/metosin/malli'>metosin/malli</a> schema to specify the shape of the data to be pulled.</p><p>The client malli schema provided is actually internally "merged" to a internal schema that checks the pattern shape so both the pattern syntax and the pattern shape are validated.</p><h2>Context</h2><p>You can provide a context to the query. You can provide a <code>modifier</code> and a <code>finalizer</code>.</p><p>This context can help you gathering information from the query and apply a function on the results.</p><h2>Lasagna Pull applied to flybot.sg</h2><p>To see Lasagna Pull in action, refer to the doc <a href='https://www.loicblanchard.me/blog/lasagna-pull-applied-to-flybot'>Lasagna Pull applied to flybot.sg</a>.</p>]]></content:encoded></item><item><title>Port your Clojure lib to the CLR with MAGIC</title><link>https://www.loicblanchard.me/blog/port-clj-lib-to-clr</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/port-clj-lib-to-clr</guid><pubDate>Fri, 08 Apr 2022 08:16:25 +0000</pubDate><description>
How to port your Clojure lib to the CLR. Then how to be build with the MAGIC compiler allowing you to obtain DLLs compatible with Unity (no DLR used by MAGIC).
</description><content:encoded><![CDATA[<p>In this article, I will show you:</p><ol><li>how to handle CLR interop to prepare your Clojure code for the CLR</li><li>how to use type hints to have your code more performant on the CLR</li><li>how to manage dependencies</li><li>how to compile to the CLR using Nostrand</li><li>how to test in the CLR using Nostrand</li></ol><p>Note: the steps for packing the code into nugget package, pushing it to remote github and fetching it in Unity are highlighted in another article.</p><h2>Rational</h2><h3>What is the Magic Compiler</h3><p>Magic is a bootsrapped compiler writhen in Clojure that take Clojure code as input and produces dotnet assemblies (.dll) as output.</p><p>Compiler Bootstrapping is the technique for producing a self-compiling compiler that is written in the same language it intends to compile. In our case, MAGIC is a <strong>Clojure</strong> compiler that compiles <strong>Clojure</strong> code to .<strong>NET</strong> assemblies (.dll and .exe files).</p><p>It means we need the old dlls of MAGIC to generate the new dlls of the MAGIC compiler. We repeat this process until the compiler is good enough. </p><p>The very first magic dlls were generated with the <a href='https://github.com/clojure/clojure-clr'>clojure/clojure-clr</a> project which is also a Clojure compiler to CLR but written in <strong>C#</strong> with limitations over the dlls generated (the problem MAGIC is intended to solve).</p><h3>Why the Magic Compiler</h3><p>The already existing clojure->clr compiler <a href='https://github.com/clojure/clojure-clr'>clojure/clojure-clr</a>. However, clojure-clr uses a technology called the DLR (dynamic language runtime) to optimize dynamic call sites but it emits self modifying code which make the assemblies not usable on mobile devices (IL2CPP in Unity). So we needed a way to have a compiler that emit assemblies that can target both Desktop and mobile (IL2CPP), hence the Magic compiler.</p><h2>Step 1: Interop</h2><h3>Reader conditionals</h3><p>We don‚Äôt want separate branches for JVM and CLR so we use reader conditionals.</p><p>You can find how to use the reader conditionals in this <a href='https://clojure.org/guides/reader_conditionals'>guide</a>.</p><p>You will mainly need them for the <code>require</code> and <code>import</code> as well as the function parameters.</p><p>Don‚Äôt forget to change the extension of your file from <code>.clj</code> to <code>.cljc</code>.</p><h3>Clj-kondo Linter supporting reader conditionals</h3><p>In <code>Emacs</code> (with <code>spacemacs</code> distribution), you might encounter some lint issues if you are using reader conditionals and some configuration might be needed.</p><p>The Clojure linter library  <a href='https://github.com/clj-kondo/clj-kondo'>clj-kondo/clj-kondo</a> supports the reader conditionals.</p><p>All the instruction on how to integrate it to the editor you prefer <a href='https://github.com/clj-kondo/clj-kondo/blob/master/doc/editor-integration.md'>here</a>.</p><p>To use <a href='https://github.com/clj-kondo/clj-kondo'>clj-kondo</a> with <a href='https://github.com/syl20bnr/spacemacs'>syl20bnr/spacemacs</a>, you need the layer <a href='https://github.com/borkdude/flycheck-clj-kondo'>borkdude/flycheck-clj-kondo</a>.</p><p>However, there is no way to add configuration in the <code>.spacemacs</code> config file.</p><p>The problem is that we need to set <code>:clj</code> as the default language to be checked.</p><p>In <code>VScode</code> I did not need any config to make it work.</p><h3>Setting up the default reader conditionals of the Clj-kondo linter</h3><p>It has nothing to do with the <code>:default</code> reader conditional key such as:</p><pre><code class="clojure">#?&#40;:clj  &#40;Clojure expression&#41;
   :cljs &#40;ClojureScript expression&#41;
   :cljr &#40;Clojure CLR expression&#41;
   :default &#40;fallthrough expression&#41;&#41;
</code></pre><p>In the code above, the <code>:default</code> reader is used if none of the other reader matches the platform the code is run on. There is no need to add the <code>:default</code> tag everywhere as the code will be ran only on 2 potential environment: <code>:clj</code> and <code>:cljr</code>.</p><p>For our linter, on your Clojure environment (in case of Emacs with <a href='https://github.com/syl20bnr/spacemacs'>syl20bnr/spacemacs</a> distribution), you can highlight the codes for the <code>:clj</code> reader only.</p><p>The <code>:cljr</code> code will be displayed as comments. </p><p>To add the default <code>:clj</code> reader, we need to add it in the config file : <code>&#126;/.config/clj-kondo/config.edn</code> (to affect all our repos). It is possible to add config at project level as well as stated <a href='https://cljdoc.org/d/clj-kondo/clj-kondo/2020.09.09/doc/configuration'>here</a>.</p><p>Here is the config to setup <code>:clj</code> as default reader:</p><pre><code class="clojure">{:cljc {:features #{:clj}}}
</code></pre><p>If you don‚Äôt specify a default reader, <code>clj-kondo</code> will trigger lots of error if you don‚Äôt provide the <code>:default</code> reader because it assumes that you might run the code on a platform that doesn‚Äôt match any of the provided reader.</p><h2>Step 2 (optional):  Add type hints</h2><p>Magic supports the same shorthands as in Clojure: <a href='https://github.com/nasser/magic/blob/master/src/magic/analyzer/types.clj#L37'>Magic types shorthands</a>.</p><h3>Value Type hints</h3><p>We want to add Magic type hints in our Clojure code to prevent slow argument boxing at run time.</p><p>The main place we want to add the type hints are the function arguments such as in:</p><pre><code class="clojure">&#40;defn straights-n
  &quot;Returns all possible straights with given length of cards.&quot;
  &#91;n cards wheel?&#93;
  #?&#40;:clj  &#91;n cards wheel?&#93;
     :cljr &#91;&#94;int n cards &#94;Boolean wheel?&#93;&#41;
  &#40;...&#41;&#41;
</code></pre><p>Note the user conditionals here to not affect our Clojure codes and tests to be run on the JVM. </p><p>I did not remove the reader conditionals here (the shorthands being the same in both Clojure and Magic It would run), because we don‚Äôt want our Clojure tests to be affected and we want to keep the dynamic idiom of Clojure. Also <code>wheel?</code> could very likely have the value <code>nil</code>, passed by one of the tests, which is in fact not a boolean.</p><p>So we want to keep our type hints in the <code>:cljr</code> reader to prevent Magic from doing slow reflection but we don‚Äôt want to affect our <code>:clj</code> reader that must remain dynamic and so type free to not alter our tests.</p><h3>Ref Type hints</h3><p>One of the best benefit of type hinting for Magic is to type hint records and their fields.</p><p>Here is an example of a record fields type hinting:</p><pre><code class="clojure">&#40;defrecord GameState #?&#40;:clj  &#91;players next-pos game-over?&#93;
                        :cljr &#91;players &#94;long next-pos &#94;boolean game-over?&#93;&#41;
&#40;...&#41;&#41;
</code></pre><p>As you can see, not all fields are type hinted because for some, we don‚Äôt have a way to do so.</p><p>There is no way to type hints a collection parameter in Magic.</p><p><code>players</code> is a vector of <code>Players</code> records. We don‚Äôt have a way to type hints such type. Actually we don‚Äôt have a way to type hints a collection in Magic. In Clojure (Java), we can type hint a collection of a known types such as:</p><pre><code class="clojure">;; Clojure file
user&gt; &#40;defn f
      &quot;`poker-cards` is a vector of `PokerCard`.&quot;
      &#91;&#94;&quot;&#91;Lmyproj.PokerCard;&quot; poker-cards&#93;
         &#40;map :num poker-cards&#41;&#41;
;=&gt; #'myproj.combination/f

;; Clojure REPL
user&gt; &#40;f &#91;&#40;-&gt;PokerCard :d :3&#41; &#40;-&gt;PokerCard :c :4&#41;&#93;&#41;
;=&gt; &#40;:3 :4&#41;
</code></pre><p>However, in Magic, such thing is not possible.</p><p>parameters which are <code>maps</code> do not benefit much from type hinting because a map could be a <code>PersistentArrayMap</code>, a <code>PersistentHashMap</code> or even a <code>PersistentTreeMap</code> so we would need to just <code>&#94;clojure.lang.APersistentMap</code> just to be generic which is not really relevant.</p><p>To type hint a record as parameter, it is advices to <code>import</code> it first to avoid having to write the fully qualified namespace:</p><pre><code class="clojure">;; Import the Combination class so we can use type hint format &#94;Combination
#?&#40;:cljr &#40;:import &#91;myproj.combination Combination&#93;&#41;&#41;
</code></pre><p>Then we can type hint a parameter which is a record conveniently such as:</p><pre><code class="clojure">&#40;defn pass?
  &quot;Returns true it the combi is a pass.&quot;
  #?&#40;:clj &#91;combi&#93;
     :cljr &#91;&#94;Combination combi&#93;&#41;
  &#40;combi/empty-combi? combi&#41;&#41;
</code></pre><p>A record field can also a be a known record types such as:</p><pre><code class="clojure">&#40;defrecord Player #?&#40;:clj  &#91;combi penalty?&#93;
                     :cljr &#91;&#94;Combination combi
                            &#94;boolean penalty?&#93;&#41;&#41;
</code></pre><h3>Type hints and testing</h3><p>Since in Clojure, we tend to use simplified parameters to our function to isolate the logic being tested (a map instead of a record, nil instead of false, a namespaced keyword instead of a map etc.), naturally lots of tests will fail in the CLR because of the type hints.</p><p>We don‚Äôt want to change our test suite with domain types so you can just add a reader conditionals to the tests affected by the type hints in the CLR.</p><h3>Interop common cases</h3><h4>Normal case</h4><p>For interop, you can use the reader conditionals such as in:</p><pre><code class="clojure">&#40;defn round-perc
  &quot;Rounds the given `number`.&quot;
  &#91;number&#93;
  #?&#40;:clj  &#40;-&gt; number double Math/round&#41;
     :cljr &#40;-&gt; number double Math/Round long&#41;&#41;&#41;
</code></pre><h4>Deftype equals methods override</h4><p>For the <code>deftype</code> to work in the CLR, we need to override different equals methods than the Java ones. In Java we use <code>hashCode</code> and <code>equal</code> but in .net we use <code>hasheq</code> and <code>equiv</code>.</p><p>Here is an example on how to override such methods:</p><pre><code class="clojure">&#40;deftype MyRecord &#91;f-conj m rm&#93;
  ;; Override equals method to compare two MyRecord.
  #?@&#40;:clj
      &#91;Object
       &#40;hashCode &#91;&#95;&#93; &#40;.hashCode m&#41;&#41;
       &#40;equals &#91;&#95; other&#93;
               &#40;and &#40;instance? MyRecord other&#41; &#40;= m &#40;.m other&#41;&#41;&#41;&#41;&#93;
      :cljr
      &#91;clojure.lang.IHashEq
       &#40;hasheq &#91;&#95;&#93; &#40;hash m&#41;&#41;
       clojure.lang.IPersistentCollection
       &#40;equiv &#91;&#95; other&#93;
              &#40;and &#40;instance? MyRecord other&#41; &#40;= m &#40;.m other&#41;&#41;&#41;&#41;&#93;&#41;&#41;
</code></pre><h4>Defecord empty method override for IL2CCP</h4><p>For the <code>defrecord</code> to work in case we target <strong>IL2CPP</strong> (all our apps), you need to override the default implementation of the <code>empty</code> method such as:</p><pre><code class="clojure">&#40;defrecord PokerCard &#91;&#94;clojure.lang.Keyword suit &#94;clojure.lang.Keyword num&#93;
  #?@&#40;:cljr
      &#91;clojure.lang.IPersistentCollection
       &#40;empty &#91;&#95;&#93; nil&#41;&#93;&#41;&#41;
</code></pre><p>Note the vector required with the <strong>splicing</strong> reader conditional <code>#?@</code>.</p><h2>Step 3: Manage dependencies</h2><p>Since magic was created before <code>tools.deps</code> or <code>leiningen</code>, it has its own deps management system and the dedicated file for it is <code>project.edn</code>.</p><p>Here is an example of a project.edn:</p><pre><code class="clojure">{:name         &quot;My project&quot;
 :source-paths &#91;&quot;src&quot; &quot;test&quot;&#93;
 :dependencies &#91;&#91;:github skydread1/clr.test.check &quot;magic&quot;
                 :sha &quot;a23fe55e8b51f574a63d6b904e1f1299700153ed&quot;
                 :paths &#91;&quot;src&quot;&#93;&#93;
                &#91;:gitlab my-private-lib1 &quot;master&quot;
                 :paths &#91;&quot;src&quot;&#93;
                 :sha &quot;791ef67978796aadb9f7aa62fe24180a23480625&quot;
                 :token &quot;r7TM52xnByEbL6mfXx2x&quot;
                 :domain &quot;my.domain.sg&quot;
                 :project-id &quot;777&quot;&#93;&#93;}
</code></pre><p>Refer to the Nostrand <a href='https://github.com/nasser/nostrand/blob/master/README.md'>README</a> for more details.</p><p>So you need to add a <code>project.edn</code>at the root of your directory with other libraries.</p><h2>Step 4: Compile to the CLR</h2><h3>Nostrand</h3><p><a href='https://github.com/nasser/nostrand'>nasser/nostrand</a> is for magic what <a href='https://github.com/clojure/tools.deps.alpha'>tools.deps</a> or <a href='https://github.com/technomancy/leiningen'>leiningen</a> are for a regular Clojure project. Magic has its own dependency manager and does not use tools.deps or len because it was implemented before these deps manager came out!</p><p>You can find all the information you need to build and test your libraries in dotnet in the <a href='https://github.com/nasser/nostrand/blob/master/README.md'>README</a>.</p><p>In short, you need to clone nostrand and create a dedicated Clojure namespace at the root of your project to run function with Nostrand.</p><h3>Build your Clojure project to .net</h3><p>In my case I named my nostrand namespace <code>dotnet.clj</code>.</p><p>You cna have a look at the <a href='https://github.com/skydread1/clr.test.check/blob/magic/dotnet.clj'>clr.test.check/dotnet.clj</a>, it is a port of clojure/test.check that compiles in both JVM and CLR.</p><p>We have the following require:</p><pre><code class="clojure">&#40;:require &#91;clojure.test :refer &#91;run-all-tests&#93;&#93;
          &#91;magic.flags :as mflags&#93;&#41;
</code></pre><p>Don‚Äôt forget to set the 2 magic flags to true:</p><pre><code class="clojure">&#40;defn build
  &quot;Compiles the project to dlls.
  This function is used by `nostrand` and is called from the terminal in the root folder as:
  nos dotnet/build&quot;
  &#91;&#93;
  &#40;binding &#91;&#42;compile-path&#42;                  &quot;build&quot;
            &#42;unchecked-math&#42;                &#42;warn-on-reflection&#42;
            mflags/&#42;strongly-typed-invokes&#42; true
            mflags/&#42;direct-linking&#42;         true
            mflags/&#42;elide-meta&#42;             false&#93;
    &#40;println &quot;Compile into DLL To : &quot; &#42;compile-path&#42;&#41;
    &#40;doseq &#91;ns prod-namespaces&#93;
      &#40;println &#40;str &quot;Compiling &quot; ns&#41;&#41;
      &#40;compile ns&#41;&#41;&#41;&#41;
</code></pre><p>To build to the <code>&#42;compile-path&#42;</code> folder, just run the <code>nos</code> command at the root of your project:</p><pre><code class="clojure">nos dotnet/build
</code></pre><h2>Step 5: Test your Clojure project to .net</h2><p>Same remark as for the build section:</p><pre><code class="clojure">&#40;defn run-tests
  &quot;Run all the tests on the CLR.
  This function is used by `nostrand` and is called from the terminal in the root folder as:
  nos dotnet/run-tests&quot;
  &#91;&#93;
  &#40;binding &#91;&#42;unchecked-math&#42;                &#42;warn-on-reflection&#42;
            mflags/&#42;strongly-typed-invokes&#42; true
            mflags/&#42;direct-linking&#42;         true
            mflags/&#42;elide-meta&#42;             false&#93;
    &#40;doseq &#91;ns &#40;concat prod-namespaces test-namespaces&#41;&#93;
      &#40;require ns&#41;&#41;
    &#40;run-all-tests&#41;&#41;&#41;
</code></pre><p>To run the tests, just run the <code>nos</code> command at the root of your project:</p><pre><code class="clojure">nos dotnet/run-tests
</code></pre><h2>Example of a Clojure library ported to Magic</h2><p>An example of a Clojure library that has been ported to Magic is <a href='https://github.com/skydread1/clr.test.check/tree/magic'>skydread1/clr.test.check</a>, a fork of clojure/clr.test.check. My fork uses reader conditionals so it can be run and tested in both JVM and CLR.</p><h2>Learn more</h2><p>Now that your library is compiled to dotnet, you can learn how to package it to nuget, push it in to your host repo and import in Unity in this article:</p><ul><li><a href='https://www.loicblanchard.me/blog/clojure-in-unity'>Pack, Push and Import Clojure to Unity</a>.</li></ul>]]></content:encoded></item><item><title>MCTS applied to card games</title><link>https://www.loicblanchard.me/blog/article-mcts</link><guid isPermaLink="false">https://www.loicblanchard.me/blog/article-mcts</guid><pubDate>Fri, 13 Aug 2021 08:16:26 +0000</pubDate><description>
General principle of MCTS applied to a Clojure use case.
</description><content:encoded><![CDATA[<h2>Objective</h2><p>At <a href='https://www.flybot.sg/'>Flybot Pte Ltd</a>, we wanted to have a robot-player that can play several rounds of some of our card games (such as <code>big-two</code>) at a decent level.</p><p>The main goal of this robot-player was to take over an AFK player for instance.</p><p>We are considering using it for an offline mode with different level of difficulty.</p><p>Vocabulary:</p><ul><li><code>big-two</code>: popular Chinese Card game (ÈîÑÂ§ßÂú∞)</li><li><code>AI</code> or <code>robot</code>: refer to a robot-player in the card game.</li></ul><p>2 approaches were used:</p><ul><li><strong>MCTS</strong></li><li><strong>Domain knowledge</strong></li></ul><p>The repositories are closed-source because private to Flybot Pte. Ltd. The approaches used are generic enough so they can be applied to any kind of games.</p><p>In this article, I will explain the general principle of MCTS applied to our specific case of <code>big-two</code>.</p><h2>MCTS theory</h2><h3>What is MCTS</h3><p><strong>Monte Carlo Tree Search</strong> (MCTS) is an important algorithm behind many major successes of recent AI applications such as <strong>AlphaGo‚Äôs</strong> striking showdown in 2016.</p><p>Essentially, MCTS uses Monte Carlo simulation to accumulate value estimates to guide towards highly rewarding trajectories in the search tree. In other words, MCTS pays more attention to nodes that are more promising, so it avoids having to brute force all possibilities which is impractical to do.</p><p>At its core, MCTS consists of repeated iterations (ideally infinite, in practice constrained by computing time and resources) of 4 steps: <code>selection</code>, <code>expansion</code>, <code>simulation</code> and <code>update</code>.</p><p>For more information, this <a href='https://towardsdatascience.com/monte-carlo-tree-search-an-introduction-503d8c04e168'>MCTS article</a> explains the concept very well.</p><h3>MCTS applied to big-two</h3><p>MCTS algorithm works very well on deterministic games with perfect information. In other words, games in which each player perfectly knows the current state of the game and there are no chance events (e.g. draw a card from a deck, dice rolling) during the game.</p><p>However, there are a lot of games in which there is not one or both of the two components: these types of games are called stochastic (chance events) and games with imperfect information (partial observability of states).</p><p>Thus, in <strong>big-two</strong>, we don‚Äôt know the cards of the other players, so it is a game with imperfect information (more info in this <a href='https://teaching.csse.uwa.edu.au/units/CITS3001/project/2017/paper1.pdf'>paper</a>).</p><p>So we can apply the MCTS to <strong>big-two</strong> but we will need to do 1 of the 2 at least:</p><ul><li>Pre-select moves by filtering the dumb moves and establish a game-plan</li><li>access to hidden information (the other player‚Äôs hand). This method is called <strong>Determinization</strong> or also <strong>Perfect</strong> <strong>Information Monte Carlo Sampling</strong>.</li></ul><h2>MCTS implementation</h2><h3>Tree representation</h3><p>Our tree representation looks like this:</p><pre><code class="clojure">{:S0 {::sut/visits 11 ::sut/score &#91;7 3&#93; ::sut/chldn &#91;:S1 :S2&#93;}
 :S1 {::sut/visits 5 ::sut/score &#91;7 3&#93; ::sut/chldn &#91;:S3 :S4&#93;}
 :S3 {::sut/visits 1 ::sut/score &#91;7 3&#93;}}
</code></pre><p>In the big-two case, <code>S0</code> is the init-state, <code>S1</code> and <code>S2</code> are the children states of <code>S0</code>.</p><p><code>S1</code> is the new state after a possible play is played</p><p><code>S2</code> is the new state if another possible play is played etc.</p><p><code>S1</code> is a key of the tree map so it means it has been explored before to run simulations.</p><p><code>S1</code> has been selected 5 times.</p><p><code>S2</code> has never been explored before so it does not appear as a key.</p><p>In games when only the win matters (not the score), you could just use something like <code>::sut/wins</code>.</p><h3>Selection</h3><p>To select the child we want to run simulation from, we proceed like this:</p><ul><li>If some children have not been explored yet, we select randomly one of them</li><li>If all children have been explored already, we use the UCT to determine the child we select.</li></ul><p><code>UCT</code> is the <code>UCB</code> (Upper Confidence Bound 1) applied to trees. It provides a way to balance exploration/exploitation. You can read more about it in this <a href='https://towardsdatascience.com/the-upper-confidence-bound-ucb-bandit-algorithm-c05c2bf4c13f'>article</a>.</p><p>In the algorithm behind <strong>AlphaGo</strong>, a <strong>UCB</strong> based policy is used. More specifically, each node has an associated UCB value and during selection we always chose the child node with the highest UCB value.</p><p>The <strong>UCB1</strong> formula is the following:</p><p><img src="https://www.loicblanchard.me/assets/mcts/ucb1.png" alt="UCB1 formula" /></p><blockquote><p> With <code>xi</code> the mean node value, <code>ni</code> the number of visits of node <code>i</code>, <code>N</code> the number of visits of the parent node. </p><p></p></blockquote><p>The equation includes the 2 following components:</p><p><img src="https://www.loicblanchard.me/assets/mcts/ucb1_2.png" alt="UCB1 formula parts" /></p><p>The first part of the equation is the <code>exploitation</code> based on the <em>optimism in the fact of uncertainty</em>.</p><p>The second part of the equation is the <code>exploration</code> that allows the search to go through a very rarely visited branch from time to time to see if some good plays might be hidden there.</p><p>In the <strong>big-two</strong> case, the <code>exploitation</code> is the total number of points divided by the number of visits of the node. For every simulation of the games, we add up the number of points the AI has made. We want the average points per game simulation so we divide by the number of times we have visited the node.</p><p>In the <strong>big-two</strong> case, the <code>exploration</code> considers the number of visits of the parent node (previous state of the game) and the number of visits of the current node (current state of the game). The more we visit the parent without visiting the specific child the bigger the exploration term becomes. Thus, if we have not visited a child for a long time, since we take the <code>log10</code> of <code>N</code>, this term becomes dominant and the child will be visited once more.</p><p>The coefficient <code>c</code>, called confidence value, allows us to change the proportion of exploration we want.</p><p>To recap, The <code>UCB</code> will often return the state that led to the most points in the past simulation. However, from time to time, it will explore and return a child that did not lead to good reward in the past but that might lead to a stronger play.</p><p>The formula applied to <strong>big-two</strong> is the following:</p><p><img src="https://www.loicblanchard.me/assets/mcts/ucb_bt.png" alt="UCB1 applied to BT" /></p><h3>Expansion</h3><p>This step just consists in adding the new selected child to the tree.</p><p>In the <strong>big-two</strong> case, the newly selected state is added to the tree.</p><h3>Simulation</h3><p>For a given node (state), we run several games with everybody playing random moves and we evaluate the total score of the AI. The total amount of points taken from all the simulations is taken into account in the <strong>UCT</strong> formula explained above.</p><p>We do not consider the win because what matters in <strong>big-two</strong>, more than winning the game, is to score a lot of points (cards remaining in opponents hands) to make more money. Sometimes, it is even better to lose the game as long as the other losers have a lot of cards left in their hands. The win matters for your position in the next round however.</p><h3>Update</h3><p>After all the simulations are done, we <strong>back-propagate</strong> all the rewards (sum up the scores of each simulation) to the branch nodes.</p><h3>MCTS Iteration</h3><p>We call <code>MCTS iteration</code> the 4 steps described above: <code>expand-&gt;select-&gt;simulate-&gt;update</code></p><p>We run those 4 steps several times to have a tree that shows the path that has the most chance to lead to the best reward (highest score).</p><p>So, for each AI move, we run several MCTS iterations to build a good tree.</p><p>The more iterations we run, the more accurate the tree is but also the bigger the computing time.</p><h3>MCTS properties</h3><p>We have 2 properties that can be changed:</p><ul><li><code>nb-rollouts</code>: number of simulations per mcts iteration.</li><li><code>budget</code>:  number of mcts iterations (tree growth)</li></ul><h3>MCTS applied to a game with more than 2 players</h3><p>Having more than 2 players (4 in <strong>big-two</strong> for instance) makes the process more complex as we need to consider the score of all the players. The default way of handling this case, is to back-propagate all the players scores after different simulations. Then, each robot (position) plays to maximize their score. The UCB value will be computed for the score of the concerned robot.</p><h3>Caching</h3><p>By caching the function that returns the possible children states, we don‚Äôt have to rerun that logic when we are visiting a similar node. The node could have been visited during the simulation of another player before so it saves time.</p><p>By caching the sample function, we do not simulate the same state again. Some states might have been simulated by players before during their mcts iterations. This allows us to go directly a level down the tree without simulating the state again and reusing the rewards back-propagated by a previous move.</p><h3>Performance issue</h3><p>In Clojure, even with caching, I was not able to run a full game because it was too slow, especially at the beginning of the game which can contain hundreds of different possible moves.</p><p>For <code>{:nb-rollouts 10 :budget 30}</code> (10 simulations per state and 30 iterations of mcts), the first move can take more than a minute to compute.</p><p>As a workaround, I had the idea of using MCTS only if a few cards are remaining in the player's hands so at least the branches are not that big in the tree. I had decent results in Clojure for big-two.</p><p>For <code>{:nb-rollouts 10 :budget 30 :max-cards 16}</code> (16 total cards remaining), in Clojure, it takes less than 3 seconds.</p><p>Because of this problem, I worked on a big-two AI that only uses the <strong>domain knowledge</strong> to play.</p><h2>Domain Knowledge</h2><p>The problem with MCTS is that even if we don‚Äôt brute force all the possibilities, the computing time is still too big if we want to build the tree using random moves.</p><p>Most of the possible plays are dumb. Most of the time, we won‚Äôt break a fiver just to cover a single card for instance. In case there are no cards on table, we won‚Äôt care about having a branch for all the singles if we can play fivers. There are many situations like this. There are lots of branches we don‚Äôt need to explore at all.</p><p>As a human player, we always have a <code>game-plan</code>, meaning we arrange our cards in our hands with some combinations we want to play if possible and the combination we don‚Äôt want to ‚Äúbreak".</p><p>We can use this <code>game-plan</code> as an alternative to MCTS, at least for the first moves of the games.</p><p>The details of this <code>game-plan</code> are confidential for obvious reasons.</p><h2>Conclusion</h2><p>Having an hybrid approach, meaning using a <code>game-plan</code> for the first moves of the game when the possible plays are too numerous, and then use MCTS at the end of the game allowed us to have a decent AI we can use.</p><p>As of the time I write this article, the implementation is being tested (as part of a bigger system) and not yet in production.</p>]]></content:encoded></item></channel></rss>